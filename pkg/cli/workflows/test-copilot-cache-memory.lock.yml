# This file was automatically generated by gh-aw. DO NOT EDIT.
# To update this file, edit the corresponding .md file and run:
#   gh aw compile
# For more information: https://github.com/githubnext/gh-aw/blob/main/.github/instructions/github-agentic-workflows.instructions.md

name: "Test Copilot with Cache Memory File Share"
on:
  workflow_dispatch:
    inputs:
      task:
        default: Store this information for later
        description: Task to remember
        required: true

permissions: {}

concurrency:
  group: "gh-aw-${{ github.workflow }}"

run-name: "Test Copilot with Cache Memory File Share"

jobs:
  agent:
    runs-on: ubuntu-latest
    permissions: read-all
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
      # Cache memory file share configuration from frontmatter processed below
      - name: Create cache-memory directory
        run: |
          mkdir -p /tmp/cache-memory
          echo "Cache memory directory created at /tmp/cache-memory"
          echo "This folder provides persistent file storage across workflow runs"
          echo "LLMs and agentic tools can freely read and write files in this directory"
      - name: Cache memory file share data
        uses: actions/cache@v4
        with:
          key: memory-${{ github.workflow }}-${{ github.run_id }}
          path: /tmp/cache-memory
          restore-keys: |
            memory-${{ github.workflow }}-
            memory-
      - name: Upload cache-memory data as artifact
        uses: actions/upload-artifact@v4
        with:
          name: cache-memory
          path: /tmp/cache-memory
          retention-days: 14
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
      - name: Install GitHub Copilot CLI
        run: npm install -g @github/copilot
      - name: Setup Copilot CLI MCP Configuration
        run: |
          mkdir -p /tmp/.copilot
      - name: Setup MCPs
        run: |
          mkdir -p /tmp/mcp-config
          cat > /tmp/.copilot/mcp-config.json << 'EOF'
          {
            "mcpServers": {}
          }
          EOF
      - name: Create prompt
        env:
          GITHUB_AW_PROMPT: /tmp/aw-prompts/prompt.txt
        run: |
          mkdir -p $(dirname "$GITHUB_AW_PROMPT")
          cat > $GITHUB_AW_PROMPT << 'EOF'
          # Test Copilot with Cache Memory File Share
          
          You are a test agent that demonstrates the cache-memory functionality with Copilot engine using a simple file share approach.
          
          ## Task
          
          Your job is to:
          
          1. **Store a test task** in the cache folder using file operations
          2. **Retrieve any previous tasks** that you've stored in previous runs
          3. **Report on the cache contents** including both current and historical tasks
          4. **Use GitHub tools** to get basic repository information
          
          ## Instructions
          
          1. First, check what files exist in `/tmp/cache-memory/` from previous runs
          2. Store a new test task: "Test task for run ${{ github.run_number }}" in a file in the cache folder
          3. List all files and contents you now have in the cache folder
          4. Get basic information about this repository using the GitHub tool
          5. Provide a summary of:
            - What you found from before (if anything)
            - What you just stored
            - Basic repository information
          
          ## Expected Behavior
          
          - **First run**: Should show empty cache folder, then store the new task
          - **Subsequent runs**: Should show previously stored files, then add the new one
          - **File persistence**: Files should persist across workflow runs thanks to cache-memory
          - **Simple file access**: Uses standard file operations (no MCP server needed)
          - **Artifact upload**: Cache data is also uploaded as artifact with 14-day retention
          
          This workflow tests that the cache-memory configuration properly:
          - Creates a simple file share at `/tmp/cache-memory/`
          - Persists data between runs using GitHub Actions cache
          - Uploads cache data as artifacts with configurable retention
          - Works with Copilot engine and file operations
          - Integrates with other tools like GitHub
          
          EOF
      - name: Append cache memory instructions to prompt
        env:
          GITHUB_AW_PROMPT: /tmp/aw-prompts/prompt.txt
        run: |
          cat >> $GITHUB_AW_PROMPT << 'EOF'
          
          ---
          
          ## Cache Folder Available
          
          You have access to a persistent cache folder at `/tmp/cache-memory/` where you can read and write files to create memories and store information.
          
          - **Read/Write Access**: You can freely read from and write to any files in this folder
          - **Persistence**: Files in this folder persist across workflow runs via GitHub Actions cache
          - **Last Write Wins**: If multiple processes write to the same file, the last write will be preserved
          - **File Share**: Use this as a simple file share - organize files as you see fit
          
          Examples of what you can store:
          - `/tmp/cache-memory/notes.txt` - general notes and observations
          - `/tmp/cache-memory/preferences.json` - user preferences and settings
          - `/tmp/cache-memory/history.log` - activity history and logs
          - `/tmp/cache-memory/state/` - organized state files in subdirectories
          
          Feel free to create, read, update, and organize files in this folder as needed for your tasks.
          EOF
      - name: Print prompt to step summary
        env:
          GITHUB_AW_PROMPT: /tmp/aw-prompts/prompt.txt
        run: |
          echo "## Generated Prompt" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '``````markdown' >> $GITHUB_STEP_SUMMARY
          cat $GITHUB_AW_PROMPT >> $GITHUB_STEP_SUMMARY
          echo '``````' >> $GITHUB_STEP_SUMMARY
      - name: Generate agentic run info
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            
            const awInfo = {
              engine_id: "copilot",
              engine_name: "GitHub Copilot CLI",
              model: "",
              version: "",
              workflow_name: "Test Copilot with Cache Memory File Share",
              experimental: true,
              supports_tools_allowlist: true,
              supports_http_transport: true,
              run_id: context.runId,
              run_number: context.runNumber,
              run_attempt: process.env.GITHUB_RUN_ATTEMPT,
              repository: context.repo.owner + '/' + context.repo.repo,
              ref: context.ref,
              sha: context.sha,
              actor: context.actor,
              event_name: context.eventName,
              staged: false,
              created_at: new Date().toISOString()
            };
            
            // Write to /tmp directory to avoid inclusion in PR
            const tmpPath = '/tmp/aw_info.json';
            fs.writeFileSync(tmpPath, JSON.stringify(awInfo, null, 2));
            console.log('Generated aw_info.json at:', tmpPath);
            console.log(JSON.stringify(awInfo, null, 2));
            
            // Add agentic workflow run information to step summary
            core.summary
              .addRaw('## Agentic Run Information\n\n')
              .addRaw('```json\n')
              .addRaw(JSON.stringify(awInfo, null, 2))
              .addRaw('\n```\n')
              .write();
      - name: Upload agentic run info
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: aw_info.json
          path: /tmp/aw_info.json
          if-no-files-found: warn
      - name: Execute GitHub Copilot CLI
        id: agentic_execution
        timeout-minutes: 5
        run: |
          set -o pipefail
          
          INSTRUCTION=$(cat /tmp/aw-prompts/prompt.txt)
          
          # Run copilot CLI with log capture
          copilot --add-dir /tmp/ --log-level debug --log-dir /tmp/.copilot/logs/ --add-dir /tmp/cache-memory/ --prompt "$INSTRUCTION" 2>&1 | tee /tmp/test-copilot-with-cache-memory-file-share.log
        env:
          GITHUB_STEP_SUMMARY: ${{ env.GITHUB_STEP_SUMMARY }}
          GITHUB_TOKEN: ${{ secrets.COPILOT_CLI_TOKEN  }}
          XDG_CONFIG_HOME: /tmp/.copilot/
          XDG_STATE_HOME: /tmp/.copilot/
      - name: Ensure log file exists
        if: always()
        run: |
          # Ensure log file exists
          touch /tmp/test-copilot-with-cache-memory-file-share.log
          # Show last few lines for debugging
          echo "=== Last 10 lines of Copilot execution log ==="
          tail -10 /tmp/test-copilot-with-cache-memory-file-share.log || echo "No log content available"
      - name: Upload engine output files
        uses: actions/upload-artifact@v4
        with:
          name: agent_outputs
          path: |
            /tmp/.copilot/logs/
          if-no-files-found: ignore
      - name: Upload MCP logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mcp-logs
          path: /tmp/mcp-logs/
          if-no-files-found: ignore
      - name: Parse agent logs for step summary
        if: always()
        uses: actions/github-script@v8
        env:
          GITHUB_AW_AGENT_OUTPUT: /tmp/test-copilot-with-cache-memory-file-share.log
        with:
          script: |
            function main() {
              const fs = require("fs");
              try {
                const logFile = process.env.AGENT_LOG_FILE;
                if (!logFile) {
                  console.log("No agent log file specified");
                  return;
                }
                if (!fs.existsSync(logFile)) {
                  console.log(`Log file not found: ${logFile}`);
                  return;
                }
                const content = fs.readFileSync(logFile, "utf8");
                const parsedLog = parseCopilotLog(content);
                if (parsedLog) {
                  core.summary.addRaw(parsedLog).write();
                  console.log("Copilot log parsed successfully");
                } else {
                  console.log("Failed to parse Copilot log");
                }
              } catch (error) {
                core.setFailed(error.message);
              }
            }
            function parseCopilotLog(logContent) {
              try {
                const lines = logContent.split("\n");
                let markdown = "## 🤖 GitHub Copilot CLI Execution\n\n";
                let hasOutput = false;
                let inCodeBlock = false;
                let currentCodeBlock = "";
                let currentLanguage = "";
                for (const line of lines) {
                  if (line.trim().startsWith("```")) {
                    if (!inCodeBlock) {
                      inCodeBlock = true;
                      currentLanguage = line.trim().substring(3);
                      currentCodeBlock = "";
                    } else {
                      inCodeBlock = false;
                      if (currentCodeBlock.trim()) {
                        markdown += `\`\`\`${currentLanguage}\n${currentCodeBlock}\`\`\`\n\n`;
                        hasOutput = true;
                      }
                      currentCodeBlock = "";
                      currentLanguage = "";
                    }
                    continue;
                  }
                  if (inCodeBlock) {
                    currentCodeBlock += line + "\n";
                    continue;
                  }
                  if (line.includes("copilot -p") || line.includes("github copilot")) {
                    markdown += `**Command:** \`${line.trim()}\`\n\n`;
                    hasOutput = true;
                  }
                  if (line.includes("Suggestion:") || line.includes("Response:")) {
                    markdown += `**${line.trim()}**\n\n`;
                    hasOutput = true;
                  }
                  if (line.toLowerCase().includes("error:")) {
                    markdown += `❌ **Error:** ${line.trim()}\n\n`;
                    hasOutput = true;
                  } else if (line.toLowerCase().includes("warning:")) {
                    markdown += `⚠️ **Warning:** ${line.trim()}\n\n`;
                    hasOutput = true;
                  }
                  const trimmedLine = line.trim();
                  if (
                    trimmedLine &&
                    !trimmedLine.startsWith("$") &&
                    !trimmedLine.startsWith("#") &&
                    !trimmedLine.match(/^\d{4}-\d{2}-\d{2}/) && 
                    trimmedLine.length > 10
                  ) {
                    if (
                      trimmedLine.includes("copilot") ||
                      trimmedLine.includes("suggestion") ||
                      trimmedLine.includes("generate") ||
                      trimmedLine.includes("explain")
                    ) {
                      markdown += `${trimmedLine}\n\n`;
                      hasOutput = true;
                    }
                  }
                }
                if (inCodeBlock && currentCodeBlock.trim()) {
                  markdown += `\`\`\`${currentLanguage}\n${currentCodeBlock}\`\`\`\n\n`;
                  hasOutput = true;
                }
                if (!hasOutput) {
                  markdown += "*No significant output captured from Copilot CLI execution.*\n";
                }
                return markdown;
              } catch (error) {
                console.error("Error parsing Copilot log:", error);
                return `## 🤖 GitHub Copilot CLI Execution\n\n*Error parsing log: ${error.message}*\n`;
              }
            }
            main();
      - name: Upload agent logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-copilot-with-cache-memory-file-share.log
          path: /tmp/test-copilot-with-cache-memory-file-share.log
          if-no-files-found: warn
      - name: Validate agent logs for errors
        if: always()
        uses: actions/github-script@v8
        env:
          GITHUB_AW_AGENT_OUTPUT: /tmp/test-copilot-with-cache-memory-file-share.log
          GITHUB_AW_ERROR_PATTERNS: "[{\"pattern\":\"(\\\\d{4}-\\\\d{2}-\\\\d{2}T\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}Z)\\\\s+\\\\[(ERROR)\\\\]\\\\s+(.+)\",\"level_group\":2,\"message_group\":3,\"description\":\"Copilot CLI timestamped ERROR messages\"},{\"pattern\":\"(\\\\d{4}-\\\\d{2}-\\\\d{2}T\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}Z)\\\\s+\\\\[(WARN|WARNING)\\\\]\\\\s+(.+)\",\"level_group\":2,\"message_group\":3,\"description\":\"Copilot CLI timestamped WARNING messages\"},{\"pattern\":\"\\\\[(\\\\d{4}-\\\\d{2}-\\\\d{2}T\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}Z)\\\\]\\\\s+(CRITICAL|ERROR):\\\\s+(.+)\",\"level_group\":2,\"message_group\":3,\"description\":\"Copilot CLI bracketed critical/error messages with timestamp\"},{\"pattern\":\"\\\\[(\\\\d{4}-\\\\d{2}-\\\\d{2}T\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}Z)\\\\]\\\\s+(WARNING):\\\\s+(.+)\",\"level_group\":2,\"message_group\":3,\"description\":\"Copilot CLI bracketed warning messages with timestamp\"},{\"pattern\":\"(Error):\\\\s+(.+)\",\"level_group\":1,\"message_group\":2,\"description\":\"Generic error messages from Copilot CLI or Node.js\"},{\"pattern\":\"npm ERR!\\\\s+(.+)\",\"level_group\":0,\"message_group\":1,\"description\":\"NPM error messages during Copilot CLI installation or execution\"},{\"pattern\":\"(Warning):\\\\s+(.+)\",\"level_group\":1,\"message_group\":2,\"description\":\"Generic warning messages from Copilot CLI\"},{\"pattern\":\"(Fatal error):\\\\s+(.+)\",\"level_group\":1,\"message_group\":2,\"description\":\"Fatal error messages from Copilot CLI\"},{\"pattern\":\"copilot:\\\\s+(error):\\\\s+(.+)\",\"level_group\":1,\"message_group\":2,\"description\":\"Copilot CLI command-level error messages\"}]"
        with:
          script: |
            function main() {
              const fs = require("fs");
              try {
                const logFile = process.env.GITHUB_AW_AGENT_OUTPUT;
                if (!logFile) {
                  throw new Error("GITHUB_AW_AGENT_OUTPUT environment variable is required");
                }
                if (!fs.existsSync(logFile)) {
                  throw new Error(`Log file not found: ${logFile}`);
                }
                const patterns = getErrorPatternsFromEnv();
                if (patterns.length === 0) {
                  throw new Error("GITHUB_AW_ERROR_PATTERNS environment variable is required and must contain at least one pattern");
                }
                const content = fs.readFileSync(logFile, "utf8");
                const hasErrors = validateErrors(content, patterns);
                if (hasErrors) {
                  core.setFailed("Errors detected in agent logs - failing workflow step");
                } else {
                  core.info("Error validation completed successfully");
                }
              } catch (error) {
                console.debug(error);
                core.setFailed(`Error validating log: ${error instanceof Error ? error.message : String(error)}`);
              }
            }
            function getErrorPatternsFromEnv() {
              const patternsEnv = process.env.GITHUB_AW_ERROR_PATTERNS;
              if (!patternsEnv) {
                throw new Error("GITHUB_AW_ERROR_PATTERNS environment variable is required");
              }
              try {
                const patterns = JSON.parse(patternsEnv);
                if (!Array.isArray(patterns)) {
                  throw new Error("GITHUB_AW_ERROR_PATTERNS must be a JSON array");
                }
                return patterns;
              } catch (e) {
                throw new Error(`Failed to parse GITHUB_AW_ERROR_PATTERNS as JSON: ${e instanceof Error ? e.message : String(e)}`);
              }
            }
            function validateErrors(logContent, patterns) {
              const lines = logContent.split("\n");
              let hasErrors = false;
              for (const pattern of patterns) {
                const regex = new RegExp(pattern.pattern, "g");
                for (let lineIndex = 0; lineIndex < lines.length; lineIndex++) {
                  const line = lines[lineIndex];
                  let match;
                  while ((match = regex.exec(line)) !== null) {
                    const level = extractLevel(match, pattern);
                    const message = extractMessage(match, pattern, line);
                    const errorMessage = `Line ${lineIndex + 1}: ${message} (Pattern: ${pattern.description || "Unknown pattern"}, Raw log: ${truncateString(line.trim(), 120)})`;
                    if (level.toLowerCase() === "error") {
                      core.error(errorMessage);
                      hasErrors = true;
                    } else {
                      core.warning(errorMessage);
                    }
                  }
                }
              }
              return hasErrors;
            }
            function extractLevel(match, pattern) {
              if (pattern.level_group && pattern.level_group > 0 && match[pattern.level_group]) {
                return match[pattern.level_group];
              }
              const fullMatch = match[0];
              if (fullMatch.toLowerCase().includes("error")) {
                return "error";
              } else if (fullMatch.toLowerCase().includes("warn")) {
                return "warning";
              }
              return "unknown";
            }
            function extractMessage(match, pattern, fullLine) {
              if (pattern.message_group && pattern.message_group > 0 && match[pattern.message_group]) {
                return match[pattern.message_group].trim();
              }
              return match[0] || fullLine.trim();
            }
            function truncateString(str, maxLength) {
              if (!str) return "";
              if (str.length <= maxLength) return str;
              return str.substring(0, maxLength) + "...";
            }
            if (typeof module !== "undefined" && module.exports) {
              module.exports = {
                validateErrors,
                extractLevel,
                extractMessage,
                getErrorPatternsFromEnv,
                truncateString,
              };
            }
            if (typeof module === "undefined" || require.main === module) {
              main();
            }

