package cli

import (
	"encoding/json"
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"github.com/githubnext/gh-aw/pkg/campaign"
	"github.com/githubnext/gh-aw/pkg/console"
	"github.com/githubnext/gh-aw/pkg/logger"
	"github.com/githubnext/gh-aw/pkg/workflow"
	"gopkg.in/yaml.v3"
)

var compileOrchestratorLog = logger.New("cli:compile_orchestrator")

// getRepositoryRelativePath converts an absolute file path to a repository-relative path
// This ensures stable workflow identifiers regardless of where the repository is cloned
func getRepositoryRelativePath(absPath string) (string, error) {
	// Get the repository root for the specific file
	repoRoot, err := findGitRootForPath(absPath)
	if err != nil {
		// If we can't get the repo root, just use the basename as fallback
		compileOrchestratorLog.Printf("Warning: could not get repository root for %s: %v, using basename", absPath, err)
		return filepath.Base(absPath), nil
	}

	// Convert both paths to absolute to ensure they can be compared
	absPath, err = filepath.Abs(absPath)
	if err != nil {
		return "", fmt.Errorf("failed to get absolute path: %w", err)
	}

	// Get the relative path from repo root
	relPath, err := filepath.Rel(repoRoot, absPath)
	if err != nil {
		return "", fmt.Errorf("failed to get relative path: %w", err)
	}

	// Normalize path separators to forward slashes for consistency across platforms
	// This ensures the same hash value on Windows, Linux, and macOS
	relPath = filepath.ToSlash(relPath)

	return relPath, nil
}

func renderGeneratedCampaignOrchestratorMarkdown(data *workflow.WorkflowData, sourceCampaignPath string) string {
	// Produce a conventional gh-aw workflow markdown file so users can review
	// the generated orchestrator and recompile it like any other workflow.
	b := &strings.Builder{}
	b.WriteString("---\n")
	if strings.TrimSpace(data.Name) != "" {
		b.WriteString(fmt.Sprintf("name: %q\n", data.Name))
	}
	if strings.TrimSpace(data.Description) != "" {
		b.WriteString(fmt.Sprintf("description: %q\n", data.Description))
	}
	if strings.TrimSpace(data.On) != "" {
		b.WriteString(strings.TrimSuffix(data.On, "\n"))
		b.WriteString("\n")
	}
	if strings.TrimSpace(data.Concurrency) != "" {
		b.WriteString(strings.TrimSuffix(data.Concurrency, "\n"))
		b.WriteString("\n")
	}

	// Make the orchestrator runnable by default.
	b.WriteString("engine: copilot\n")

	// Render safe-outputs if configured by the campaign orchestrator generator.
	// This enables campaign orchestrators to update their Projects dashboard and
	// post tracker comments without requiring manual edits to generated files.
	if data.SafeOutputs != nil {
		// NOTE: We must emit the public frontmatter keys (e.g. "add-comment") rather
		// than the internal struct YAML tags (e.g. "add-comments").
		outputs := map[string]any{}
		if data.SafeOutputs.AddComments != nil {
			outputs["add-comment"] = map[string]any{
				"max": data.SafeOutputs.AddComments.Max,
			}
		}
		if data.SafeOutputs.UpdateProjects != nil {
			updateProjectConfig := map[string]any{
				"max": data.SafeOutputs.UpdateProjects.Max,
			}
			// Include github-token if specified
			if strings.TrimSpace(data.SafeOutputs.UpdateProjects.GitHubToken) != "" {
				updateProjectConfig["github-token"] = data.SafeOutputs.UpdateProjects.GitHubToken
			}
			outputs["update-project"] = updateProjectConfig
		}
		if len(outputs) > 0 {
			payload := map[string]any{"safe-outputs": outputs}
			if out, err := yaml.Marshal(payload); err == nil {
				b.WriteString(string(out))
			} else {
				compileOrchestratorLog.Printf("Failed to render safe-outputs for generated campaign orchestrator: %v", err)
			}
		}
	}

	// Intentionally omit permissions from generated campaign orchestrator frontmatter.
	// Workflow/job permissions are handled during compilation.
	if strings.TrimSpace(data.RunsOn) != "" {
		b.WriteString(strings.TrimSuffix(data.RunsOn, "\n"))
		b.WriteString("\n")
	}
	if len(data.Roles) > 0 {
		b.WriteString("roles:\n")
		for _, role := range data.Roles {
			if strings.TrimSpace(role) == "" {
				continue
			}
			b.WriteString(fmt.Sprintf("  - %q\n", role))
		}
	}
	b.WriteString("---\n\n")
	// Include version for released builds only (not "dev", "dirty", or "test")
	version := workflow.GetVersion()
	if workflow.IsReleasedVersion(version) {
		b.WriteString(fmt.Sprintf("<!-- This file was automatically generated by gh-aw (%s). DO NOT EDIT. -->\n", version))
	} else {
		b.WriteString("<!-- This file was automatically generated by gh-aw. DO NOT EDIT. -->\n")
	}
	if strings.TrimSpace(sourceCampaignPath) != "" {
		// Normalize path to be relative to git root (where .github folder exists)
		// This ensures stable paths regardless of current working directory
		relativePath := ToGitRootRelativePath(sourceCampaignPath)
		b.WriteString(fmt.Sprintf("<!-- Source: %s -->\n", relativePath))
	}
	b.WriteString("\n")
	b.WriteString(strings.TrimSpace(data.MarkdownContent))
	b.WriteString("\n")
	return b.String()
}

func generateAndCompileCampaignOrchestrator(
	compiler *workflow.Compiler,
	spec *campaign.CampaignSpec,
	campaignSpecPath string,
	verbose bool,
	noEmit bool,
	runZizmorPerFile bool,
	runPoutinePerFile bool,
	runActionlintPerFile bool,
	strict bool,
	validateActionSHAs bool,
) (string, error) {
	data, orchestratorPath := campaign.BuildOrchestrator(spec, campaignSpecPath)
	if data == nil || orchestratorPath == "" {
		return "", nil
	}

	// Ensure we pick a real engine in the YAML compiler path.
	if strings.TrimSpace(data.AI) == "" {
		data.AI = "copilot"
	}

	if !noEmit {
		content := renderGeneratedCampaignOrchestratorMarkdown(data, campaignSpecPath)
		if err := os.WriteFile(orchestratorPath, []byte(content), 0644); err != nil {
			return "", fmt.Errorf("failed to write generated campaign orchestrator %s: %w", orchestratorPath, err)
		}
		if verbose {
			fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Generated campaign orchestrator %s", filepath.Base(orchestratorPath))))
		}
	}

	// Prefer compiling from the generated markdown so defaults and validation behavior
	// match normal workflows (including computed permissions).
	if !noEmit {
		if err := CompileWorkflowWithValidation(compiler, orchestratorPath, verbose, runZizmorPerFile, runPoutinePerFile, runActionlintPerFile, strict, validateActionSHAs); err != nil {
			return orchestratorPath, err
		}
		return orchestratorPath, nil
	}

	// No-emit mode: compile from the in-memory WorkflowData.
	if err := CompileWorkflowDataWithValidation(compiler, data, orchestratorPath, verbose, runZizmorPerFile, runPoutinePerFile, runActionlintPerFile, strict, validateActionSHAs); err != nil {
		return orchestratorPath, err
	}

	return orchestratorPath, nil
}

// CompileWorkflows compiles workflows based on the provided configuration
func CompileWorkflows(config CompileConfig) ([]*workflow.WorkflowData, error) {
	markdownFiles := config.MarkdownFiles
	verbose := config.Verbose
	engineOverride := config.EngineOverride
	validate := config.Validate
	watch := config.Watch
	workflowDir := config.WorkflowDir
	noEmit := config.NoEmit
	purge := config.Purge
	trialMode := config.TrialMode
	trialLogicalRepoSlug := config.TrialLogicalRepoSlug
	strict := config.Strict
	dependabot := config.Dependabot
	forceOverwrite := config.ForceOverwrite
	zizmor := config.Zizmor
	poutine := config.Poutine
	actionlint := config.Actionlint
	jsonOutput := config.JSONOutput

	compileOrchestratorLog.Printf("Starting workflow compilation: files=%d, validate=%v, watch=%v, noEmit=%v, dependabot=%v, zizmor=%v, poutine=%v, actionlint=%v, jsonOutput=%v", len(markdownFiles), validate, watch, noEmit, dependabot, zizmor, poutine, actionlint, jsonOutput)

	// Track compilation statistics
	stats := &CompilationStats{}

	// Track validation results for JSON output
	var validationResults []ValidationResult

	// Validate configuration
	if err := validateCompileConfig(config); err != nil {
		return nil, err
	}

	// Validate and set default for workflow directory
	if workflowDir == "" {
		workflowDir = ".github/workflows"
		compileOrchestratorLog.Printf("Using default workflow directory: %s", workflowDir)
	} else {
		// Clean the path to avoid issues with ".." or other problematic elements
		workflowDir = filepath.Clean(workflowDir)
		compileOrchestratorLog.Printf("Using custom workflow directory: %s", workflowDir)
	}

	// Create compiler with verbose flag and AI engine override
	compiler := workflow.NewCompiler(verbose, engineOverride, GetVersion())
	compileOrchestratorLog.Print("Created compiler instance")

	// Set repository slug for schedule scattering
	repoSlug := getRepositorySlugFromRemote()
	if repoSlug != "" {
		compiler.SetRepositorySlug(repoSlug)
		compileOrchestratorLog.Printf("Repository slug set: %s", repoSlug)
	}

	// Set validation based on the validate flag (false by default for compatibility)
	compiler.SetSkipValidation(!validate)
	compileOrchestratorLog.Printf("Validation enabled: %v", validate)

	// Set noEmit flag to validate without generating lock files
	compiler.SetNoEmit(noEmit)
	if noEmit {
		compileOrchestratorLog.Print("No-emit mode enabled: validating without generating lock files")
	}

	// Set strict mode if specified
	compiler.SetStrictMode(strict)

	// Set trial mode if specified
	if trialMode {
		compileOrchestratorLog.Printf("Enabling trial mode: repoSlug=%s", trialLogicalRepoSlug)
		compiler.SetTrialMode(true)
		if trialLogicalRepoSlug != "" {
			compiler.SetTrialLogicalRepoSlug(trialLogicalRepoSlug)
		}
	}

	// Set refresh stop time flag
	compiler.SetRefreshStopTime(config.RefreshStopTime)
	if config.RefreshStopTime {
		compileOrchestratorLog.Print("Stop time refresh enabled: will regenerate stop-after times")
	}

	// Set action mode if specified
	if config.ActionMode != "" {
		mode := workflow.ActionMode(config.ActionMode)
		if !mode.IsValid() {
			return nil, fmt.Errorf("invalid action mode '%s'. Must be 'inline', 'dev', or 'release'", config.ActionMode)
		}
		compiler.SetActionMode(mode)
		compileOrchestratorLog.Printf("Action mode set to: %s", mode)
	} else {
		// Use auto-detection with version from binary
		mode := workflow.DetectActionMode(GetVersion())
		compiler.SetActionMode(mode)
		compileOrchestratorLog.Printf("Action mode auto-detected: %s (version: %s)", mode, GetVersion())
	}

	if watch {
		// Watch mode: watch for file changes and recompile automatically
		// For watch mode, we only support a single file for now
		var markdownFile string
		if len(markdownFiles) > 0 {
			if len(markdownFiles) > 1 {
				fmt.Fprintln(os.Stderr, console.FormatWarningMessage("Watch mode only supports a single file, using the first one"))
			}
			// Resolve the workflow file to get the full path
			resolvedFile, err := resolveWorkflowFile(markdownFiles[0], verbose)
			if err != nil {
				return nil, fmt.Errorf("failed to resolve workflow '%s': %w", markdownFiles[0], err)
			}
			markdownFile = resolvedFile
		}
		return nil, watchAndCompileWorkflows(markdownFile, compiler, verbose)
	}

	var workflowDataList []*workflow.WorkflowData

	if len(markdownFiles) > 0 {
		compileOrchestratorLog.Printf("Compiling %d specific workflow files", len(markdownFiles))
		// Compile specific workflow files
		var compiledCount int
		var errorCount int
		var errorMessages []string
		for _, markdownFile := range markdownFiles {
			stats.Total++

			// Initialize validation result for this workflow
			result := ValidationResult{
				Workflow: markdownFile,
				Valid:    true,
				Errors:   []ValidationError{},
				Warnings: []ValidationError{},
			}

			// Resolve workflow ID or file path to actual file path
			compileOrchestratorLog.Printf("Resolving workflow file: %s", markdownFile)
			resolvedFile, err := resolveWorkflowFile(markdownFile, verbose)
			if err != nil {
				if !jsonOutput {
					// Print the error directly - it already contains suggestions and formatting
					fmt.Fprintln(os.Stderr, err.Error())
				}
				errorMessages = append(errorMessages, err.Error())
				errorCount++
				stats.Errors++
				trackWorkflowFailure(stats, markdownFile, 1)

				// Add to validation results
				result.Valid = false
				result.Errors = append(result.Errors, ValidationError{
					Type:    "resolution_error",
					Message: err.Error(),
				})
				validationResults = append(validationResults, result)
				continue
			}
			compileOrchestratorLog.Printf("Resolved to: %s", resolvedFile)

			// Update result with resolved file name
			result.Workflow = filepath.Base(resolvedFile)

			// Handle campaign spec files separately from regular workflows
			if strings.HasSuffix(resolvedFile, ".campaign.md") {
				// Validate the campaign spec file and referenced workflows instead of
				// compiling it as a regular workflow YAML.
				spec, problems, vErr := campaign.ValidateSpecFromFile(resolvedFile)
				if vErr != nil {
					errMsg := fmt.Sprintf("failed to validate campaign spec %s: %v", resolvedFile, vErr)
					if !jsonOutput {
						fmt.Fprintln(os.Stderr, console.FormatErrorMessage(errMsg))
					}
					errorMessages = append(errorMessages, vErr.Error())
					errorCount++
					stats.Errors++
					trackWorkflowFailure(stats, resolvedFile, 1)

					result.Valid = false
					result.Errors = append(result.Errors, ValidationError{
						Type:    "campaign_validation_error",
						Message: vErr.Error(),
					})
					validationResults = append(validationResults, result)
					continue
				}

				// Also ensure that workflows referenced by the campaign spec exist
				workflowsDir := filepath.Dir(resolvedFile)
				workflowProblems := campaign.ValidateWorkflowsExist(spec, workflowsDir)
				problems = append(problems, workflowProblems...)

				if len(problems) > 0 {
					for _, p := range problems {
						if !jsonOutput {
							fmt.Fprintln(os.Stderr, console.FormatErrorMessage(p))
						}
						result.Valid = false
						result.Errors = append(result.Errors, ValidationError{
							Type:    "campaign_validation_error",
							Message: p,
						})
					}
					errorMessages = append(errorMessages, problems[0])
					errorCount++
					stats.Errors++
					trackWorkflowFailure(stats, resolvedFile, len(problems))
				} else {
					if verbose && !jsonOutput {
						fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Validated campaign spec %s", filepath.Base(resolvedFile))))
					}

					if _, genErr := generateAndCompileCampaignOrchestrator(
						compiler,
						spec,
						resolvedFile,
						verbose && !jsonOutput,
						noEmit,
						zizmor && !noEmit,
						poutine && !noEmit,
						actionlint && !noEmit,
						strict,
						validate && !noEmit,
					); genErr != nil {
						errMsg := fmt.Sprintf("failed to compile campaign orchestrator for %s: %v", filepath.Base(resolvedFile), genErr)
						if !jsonOutput {
							fmt.Fprintln(os.Stderr, console.FormatErrorMessage(errMsg))
						}
						errorMessages = append(errorMessages, errMsg)
						errorCount++
						stats.Errors++
						trackWorkflowFailure(stats, resolvedFile, 1)
						result.Valid = false
						result.Errors = append(result.Errors, ValidationError{Type: "campaign_orchestrator_error", Message: errMsg})
					}
				}

				validationResults = append(validationResults, result)
				continue
			}

			lockFile := strings.TrimSuffix(resolvedFile, ".md") + ".lock.yml"
			if !noEmit {
				result.CompiledFile = lockFile
			}

			// Parse workflow file to get data
			compileOrchestratorLog.Printf("Parsing workflow file: %s", resolvedFile)
			// Set workflow identifier for schedule scattering (use repository-relative path for stability)
			relPath, err := getRepositoryRelativePath(resolvedFile)
			if err != nil {
				compileOrchestratorLog.Printf("Warning: failed to get repository-relative path for %s: %v", resolvedFile, err)
				// Fallback to basename if we can't get relative path
				relPath = filepath.Base(resolvedFile)
			}
			compiler.SetWorkflowIdentifier(relPath)

			// Set repository slug for this specific file (may differ from CWD's repo)
			fileRepoSlug := getRepositorySlugFromRemoteForPath(resolvedFile)
			if fileRepoSlug != "" {
				compiler.SetRepositorySlug(fileRepoSlug)
				compileOrchestratorLog.Printf("Repository slug for file set: %s", fileRepoSlug)
			}

			workflowData, err := compiler.ParseWorkflowFile(resolvedFile)
			if err != nil {
				errMsg := fmt.Sprintf("failed to parse workflow file %s: %v", resolvedFile, err)
				if !jsonOutput {
					fmt.Fprintln(os.Stderr, console.FormatErrorMessage(errMsg))
				}
				errorMessages = append(errorMessages, err.Error())
				errorCount++
				stats.Errors++
				trackWorkflowFailure(stats, resolvedFile, 1)

				// Add to validation results
				result.Valid = false
				result.Errors = append(result.Errors, ValidationError{
					Type:    "parse_error",
					Message: err.Error(),
				})
				validationResults = append(validationResults, result)
				continue
			}
			workflowDataList = append(workflowDataList, workflowData)

			compileOrchestratorLog.Printf("Starting compilation of %s", resolvedFile)
			if err := CompileWorkflowDataWithValidation(compiler, workflowData, resolvedFile, verbose && !jsonOutput, zizmor && !noEmit, poutine && !noEmit, actionlint && !noEmit, strict, validate && !noEmit); err != nil {
				// Always put error on a new line and don't wrap with "failed to compile workflow"
				if !jsonOutput {
					fmt.Fprintln(os.Stderr, err.Error())
				}
				errorMessages = append(errorMessages, err.Error())
				errorCount++
				stats.Errors++
				trackWorkflowFailure(stats, resolvedFile, 1)

				// Add to validation results
				result.Valid = false
				result.Errors = append(result.Errors, ValidationError{
					Type:    "compilation_error",
					Message: err.Error(),
				})
				validationResults = append(validationResults, result)
				continue
			}
			compiledCount++

			// Add successful validation result
			validationResults = append(validationResults, result)
		}

		// Get warning count from compiler
		stats.Warnings = compiler.GetWarningCount()

		// Display any schedule warnings from this compiler instance
		scheduleWarnings := compiler.GetScheduleWarnings()
		if len(scheduleWarnings) > 0 && !jsonOutput {
			for _, warning := range scheduleWarnings {
				fmt.Fprintln(os.Stderr, console.FormatWarningMessage(warning))
			}
		}

		if verbose {
			fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Successfully compiled %d workflow file(s)", compiledCount)))
		}

		// Get the action cache once for use in multiple places
		actionCache := compiler.GetSharedActionCache()
		hasActionCacheEntries := actionCache != nil && len(actionCache.Entries) > 0

		// Ensure .gitattributes marks .lock.yml files as generated
		// Only update if we successfully compiled workflows or have action cache entries
		if compiledCount > 0 || hasActionCacheEntries {
			compileOrchestratorLog.Printf("Updating .gitattributes (compiled=%d, actionCache=%v)", compiledCount, hasActionCacheEntries)
			if err := ensureGitAttributes(); err != nil {
				compileOrchestratorLog.Printf("Failed to update .gitattributes: %v", err)
				if verbose {
					fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to update .gitattributes: %v", err)))
				}
			} else {
				compileOrchestratorLog.Printf("Successfully updated .gitattributes")
				if verbose {
					fmt.Fprintln(os.Stderr, console.FormatSuccessMessage("Updated .gitattributes to mark .lock.yml files as generated"))
				}
			}
		} else {
			compileOrchestratorLog.Print("Skipping .gitattributes update (no compiled workflows and no action cache entries)")
		}

		// Generate Dependabot manifests if requested
		if dependabot && !noEmit {
			compileOrchestratorLog.Print("Generating Dependabot manifests for compiled workflows")
			// Resolve workflow directory path
			absWorkflowDir := workflowDir
			if !filepath.IsAbs(absWorkflowDir) {
				gitRoot, err := findGitRoot()
				if err == nil {
					absWorkflowDir = filepath.Join(gitRoot, workflowDir)
				}
			}

			if err := compiler.GenerateDependabotManifests(workflowDataList, absWorkflowDir, forceOverwrite); err != nil {
				if strict {
					return workflowDataList, fmt.Errorf("failed to generate Dependabot manifests: %w", err)
				}
				// Non-strict mode: just report as warning
				fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to generate Dependabot manifests: %v", err)))
			}
		}

		// Note: Instructions are only written by the init command
		// The compile command should not write instruction files

		// Validate campaign specs if they exist
		if err := validateCampaigns(workflowDir, verbose); err != nil {
			if strict {
				return workflowDataList, fmt.Errorf("campaign validation failed: %w", err)
			}
			// Non-strict mode: just report as warning
			fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Campaign validation: %v", err)))
		}

		// Collect and display workflow statistics if requested
		if config.Stats && !noEmit && !jsonOutput {
			var statsList []*WorkflowStats
			for _, file := range markdownFiles {
				resolvedFile, err := resolveWorkflowFile(file, false)
				if err != nil {
					continue // Skip files that couldn't be resolved
				}
				lockFile := strings.TrimSuffix(resolvedFile, ".md") + ".lock.yml"
				if workflowStats, err := collectWorkflowStats(lockFile); err == nil {
					statsList = append(statsList, workflowStats)
				}
			}
			displayStatsTable(statsList)
		}

		// Output JSON if requested
		if jsonOutput {
			jsonBytes, err := json.MarshalIndent(validationResults, "", "  ")
			if err != nil {
				return workflowDataList, fmt.Errorf("failed to marshal JSON: %w", err)
			}
			fmt.Println(string(jsonBytes))
		} else if !config.Stats {
			// Print summary for text output (skip if stats mode)
			printCompilationSummary(stats)
		}

		// Save the action cache after all compilations
		if actionCache != nil {
			if err := actionCache.Save(); err != nil {
				compileOrchestratorLog.Printf("Failed to save action cache: %v", err)
				if verbose {
					fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to save action cache: %v", err)))
				}
			} else {
				compileOrchestratorLog.Print("Action cache saved successfully")
				if verbose {
					fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Action cache saved to %s", actionCache.GetCachePath())))
				}
			}
		}

		// Return error if any compilations failed
		if errorCount > 0 {
			// Return the first error message for backward compatibility with tests
			if len(errorMessages) > 0 {
				return workflowDataList, errors.New(errorMessages[0])
			}
			return workflowDataList, fmt.Errorf("compilation failed")
		}

		return workflowDataList, nil
	}

	// Find git root for consistent behavior
	gitRoot, err := findGitRoot()
	if err != nil {
		return nil, fmt.Errorf("compile without arguments requires being in a git repository: %w", err)
	}
	compileOrchestratorLog.Printf("Found git root: %s", gitRoot)

	// Compile all markdown files in the specified workflow directory relative to git root
	workflowsDir := filepath.Join(gitRoot, workflowDir)
	if _, err := os.Stat(workflowsDir); os.IsNotExist(err) {
		return nil, fmt.Errorf("the %s directory does not exist in git root (%s)", workflowDir, gitRoot)
	}

	compileOrchestratorLog.Printf("Scanning for markdown files in %s", workflowsDir)
	if verbose {
		fmt.Printf("Scanning for markdown files in %s\n", workflowsDir)
	}

	// Find all markdown files
	mdFiles, err := filepath.Glob(filepath.Join(workflowsDir, "*.md"))
	if err != nil {
		return nil, fmt.Errorf("failed to find markdown files: %w", err)
	}

	if len(mdFiles) == 0 {
		return nil, fmt.Errorf("no markdown files found in %s", workflowsDir)
	}

	compileOrchestratorLog.Printf("Found %d markdown files to compile", len(mdFiles))
	if verbose {
		fmt.Printf("Found %d markdown files to compile\n", len(mdFiles))
	}

	// Handle purge logic: collect existing .lock.yml and .invalid.yml files before compilation
	var existingLockFiles []string
	var existingInvalidFiles []string
	var expectedLockFiles []string
	if purge {
		// Find all existing .lock.yml files
		existingLockFiles, err = filepath.Glob(filepath.Join(workflowsDir, "*.lock.yml"))
		if err != nil {
			return nil, fmt.Errorf("failed to find existing lock files: %w", err)
		}

		// Find all existing .invalid.yml files
		existingInvalidFiles, err = filepath.Glob(filepath.Join(workflowsDir, "*.invalid.yml"))
		if err != nil {
			return nil, fmt.Errorf("failed to find existing invalid files: %w", err)
		}

		// Create expected lock files list based on markdown files
		for _, mdFile := range mdFiles {
			lockFile := strings.TrimSuffix(mdFile, ".md") + ".lock.yml"
			expectedLockFiles = append(expectedLockFiles, lockFile)
		}

		if verbose && len(existingLockFiles) > 0 {
			fmt.Fprintln(os.Stderr, console.FormatInfoMessage(fmt.Sprintf("Found %d existing .lock.yml files", len(existingLockFiles))))
		}
		if verbose && len(existingInvalidFiles) > 0 {
			fmt.Fprintln(os.Stderr, console.FormatInfoMessage(fmt.Sprintf("Found %d existing .invalid.yml files", len(existingInvalidFiles))))
		}
	}

	// Compile each file (including .campaign.md files)
	var errorCount int
	var successCount int
	for _, file := range mdFiles {
		stats.Total++

		// Initialize validation result for this workflow
		result := ValidationResult{
			Workflow: filepath.Base(file),
			Valid:    true,
			Errors:   []ValidationError{},
			Warnings: []ValidationError{},
		}

		// Handle campaign spec files separately from regular workflows
		if strings.HasSuffix(file, ".campaign.md") {
			// Validate the campaign spec file and referenced workflows instead of
			// compiling it as a regular workflow YAML.
			spec, problems, vErr := campaign.ValidateSpecFromFile(file)
			if vErr != nil {
				if !jsonOutput {
					fmt.Fprintln(os.Stderr, console.FormatErrorMessage(fmt.Sprintf("failed to validate campaign spec %s: %v", file, vErr)))
				}
				errorCount++
				stats.Errors++
				trackWorkflowFailure(stats, file, 1)

				result.Valid = false
				result.Errors = append(result.Errors, ValidationError{
					Type:    "campaign_validation_error",
					Message: vErr.Error(),
				})
				validationResults = append(validationResults, result)
				continue
			}

			workflowsDir := filepath.Dir(file)
			workflowProblems := campaign.ValidateWorkflowsExist(spec, workflowsDir)
			problems = append(problems, workflowProblems...)

			if len(problems) > 0 {
				for _, p := range problems {
					if !jsonOutput {
						fmt.Fprintln(os.Stderr, console.FormatErrorMessage(p))
					}
					result.Valid = false
					result.Errors = append(result.Errors, ValidationError{
						Type:    "campaign_validation_error",
						Message: p,
					})
				}
				// Treat campaign spec problems as compilation errors for this file
				errorCount++
				stats.Errors++
				trackWorkflowFailure(stats, file, len(problems))
			} else {
				if verbose && !jsonOutput {
					fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Validated campaign spec %s", filepath.Base(file))))
				}

				if _, genErr := generateAndCompileCampaignOrchestrator(
					compiler,
					spec,
					file,
					verbose && !jsonOutput,
					noEmit,
					zizmor && !noEmit,
					poutine && !noEmit,
					actionlint && !noEmit,
					strict,
					validate && !noEmit,
				); genErr != nil {
					if !jsonOutput {
						fmt.Fprintln(os.Stderr, console.FormatErrorMessage(genErr.Error()))
					}
					errorCount++
					stats.Errors++
					trackWorkflowFailure(stats, file, 1)
					result.Valid = false
					result.Errors = append(result.Errors, ValidationError{Type: "campaign_orchestrator_error", Message: genErr.Error()})
				}
			}

			validationResults = append(validationResults, result)
			continue
		}

		lockFile := strings.TrimSuffix(file, ".md") + ".lock.yml"
		if !noEmit {
			result.CompiledFile = lockFile
		}

		// Parse workflow file to get data
		// Set workflow identifier for schedule scattering (use repository-relative path for stability)
		relPath, err := getRepositoryRelativePath(file)
		if err != nil {
			compileOrchestratorLog.Printf("Warning: failed to get repository-relative path for %s: %v", file, err)
			// Fallback to basename if we can't get relative path
			relPath = filepath.Base(file)
		}
		compiler.SetWorkflowIdentifier(relPath)

		// Set repository slug for this specific file (may differ from CWD's repo)
		fileRepoSlug := getRepositorySlugFromRemoteForPath(file)
		if fileRepoSlug != "" {
			compiler.SetRepositorySlug(fileRepoSlug)
			compileOrchestratorLog.Printf("Repository slug for file set: %s", fileRepoSlug)
		}

		workflowData, err := compiler.ParseWorkflowFile(file)
		if err != nil {
			if !jsonOutput {
				fmt.Fprintln(os.Stderr, console.FormatErrorMessage(fmt.Sprintf("failed to parse workflow file %s: %v", file, err)))
			}
			errorCount++
			stats.Errors++
			trackWorkflowFailure(stats, file, 1)

			// Add to validation results
			result.Valid = false
			result.Errors = append(result.Errors, ValidationError{
				Type:    "parse_error",
				Message: err.Error(),
			})
			validationResults = append(validationResults, result)
			continue
		}
		workflowDataList = append(workflowDataList, workflowData)

		if err := CompileWorkflowDataWithValidation(compiler, workflowData, file, verbose && !jsonOutput, zizmor && !noEmit, poutine && !noEmit, actionlint && !noEmit, strict, validate && !noEmit); err != nil {
			// Print the error to stderr (errors from CompileWorkflow are already formatted)
			if !jsonOutput {
				fmt.Fprintln(os.Stderr, err.Error())
			}
			errorCount++
			stats.Errors++
			trackWorkflowFailure(stats, file, 1)

			// Add to validation results
			result.Valid = false
			result.Errors = append(result.Errors, ValidationError{
				Type:    "compilation_error",
				Message: err.Error(),
			})
			validationResults = append(validationResults, result)
			continue
		}
		successCount++

		// Add successful validation result
		validationResults = append(validationResults, result)
	}

	// Get warning count from compiler
	stats.Warnings = compiler.GetWarningCount()

	// Display any schedule warnings from this compiler instance
	scheduleWarnings := compiler.GetScheduleWarnings()
	if len(scheduleWarnings) > 0 && !jsonOutput {
		for _, warning := range scheduleWarnings {
			fmt.Fprintln(os.Stderr, console.FormatWarningMessage(warning))
		}
	}

	if verbose {
		fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Successfully compiled %d out of %d workflow files", successCount, len(mdFiles))))
	}

	// Handle purge logic: delete orphaned .lock.yml files
	if purge && len(existingLockFiles) > 0 {
		// Find lock files that should be deleted (exist but aren't expected)
		expectedLockFileSet := make(map[string]bool)
		for _, expected := range expectedLockFiles {
			expectedLockFileSet[expected] = true
		}

		var orphanedFiles []string
		for _, existing := range existingLockFiles {
			if !expectedLockFileSet[existing] {
				orphanedFiles = append(orphanedFiles, existing)
			}
		}

		// Delete orphaned lock files
		if len(orphanedFiles) > 0 {
			for _, orphanedFile := range orphanedFiles {
				if err := os.Remove(orphanedFile); err != nil {
					fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to remove orphaned lock file %s: %v", filepath.Base(orphanedFile), err)))
				} else {
					fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Removed orphaned lock file: %s", filepath.Base(orphanedFile))))
				}
			}
			if verbose {
				fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Purged %d orphaned .lock.yml files", len(orphanedFiles))))
			}
		} else if verbose {
			fmt.Fprintln(os.Stderr, console.FormatInfoMessage("No orphaned .lock.yml files found to purge"))
		}
	}

	// Handle purge logic: delete all .invalid.yml files (these should always be cleaned up)
	if purge && len(existingInvalidFiles) > 0 {
		// Delete all .invalid.yml files since these are temporary debugging artifacts
		// that should not persist after compilation
		for _, invalidFile := range existingInvalidFiles {
			if err := os.Remove(invalidFile); err != nil {
				fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to remove invalid file %s: %v", filepath.Base(invalidFile), err)))
			} else {
				fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Removed invalid file: %s", filepath.Base(invalidFile))))
			}
		}
		if verbose {
			fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Purged %d .invalid.yml files", len(existingInvalidFiles))))
		}
	}

	// Get the action cache once for use in multiple places
	actionCache := compiler.GetSharedActionCache()
	hasActionCacheEntries := actionCache != nil && len(actionCache.Entries) > 0

	// Ensure .gitattributes marks .lock.yml files as generated
	// Only update if we successfully compiled workflows or have action cache entries
	if successCount > 0 || hasActionCacheEntries {
		compileOrchestratorLog.Printf("Updating .gitattributes (compiled=%d, actionCache=%v)", successCount, hasActionCacheEntries)
		if err := ensureGitAttributes(); err != nil {
			if verbose {
				fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to update .gitattributes: %v", err)))
			}
		} else if verbose {
			fmt.Fprintln(os.Stderr, console.FormatSuccessMessage("Updated .gitattributes to mark .lock.yml files as generated"))
		}
	} else {
		compileOrchestratorLog.Print("Skipping .gitattributes update (no compiled workflows and no action cache entries)")
	}

	// Generate Dependabot manifests if requested
	if dependabot && !noEmit {
		// Use absolute path for workflow directory
		absWorkflowDir := workflowsDir
		if !filepath.IsAbs(absWorkflowDir) {
			absWorkflowDir = filepath.Join(gitRoot, workflowDir)
		}

		if err := compiler.GenerateDependabotManifests(workflowDataList, absWorkflowDir, forceOverwrite); err != nil {
			if strict {
				return workflowDataList, fmt.Errorf("failed to generate Dependabot manifests: %w", err)
			}
			// Non-strict mode: just report as warning
			fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to generate Dependabot manifests: %v", err)))
		}
	}

	// Generate maintenance workflow if any workflow uses expires field
	if !noEmit {
		absWorkflowDir := workflowsDir
		if !filepath.IsAbs(absWorkflowDir) {
			absWorkflowDir = filepath.Join(gitRoot, workflowDir)
		}

		if err := workflow.GenerateMaintenanceWorkflow(workflowDataList, absWorkflowDir, verbose); err != nil {
			if strict {
				return workflowDataList, fmt.Errorf("failed to generate maintenance workflow: %w", err)
			}
			// Non-strict mode: just report as warning
			fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to generate maintenance workflow: %v", err)))
		}
	}

	// Note: Instructions are only written by the init command
	// The compile command should not write instruction files

	// Validate campaign specs if they exist
	if err := validateCampaigns(workflowDir, verbose); err != nil {
		if strict {
			return workflowDataList, fmt.Errorf("campaign validation failed: %w", err)
		}
		// Non-strict mode: just report as warning
		fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Campaign validation: %v", err)))
	}

	// Collect and display workflow statistics if requested
	if config.Stats && !noEmit && !jsonOutput {
		var statsList []*WorkflowStats
		for _, file := range mdFiles {
			lockFile := strings.TrimSuffix(file, ".md") + ".lock.yml"
			if workflowStats, err := collectWorkflowStats(lockFile); err == nil {
				statsList = append(statsList, workflowStats)
			}
		}
		displayStatsTable(statsList)
	}

	// Output JSON if requested
	if jsonOutput {
		jsonBytes, err := json.MarshalIndent(validationResults, "", "  ")
		if err != nil {
			return workflowDataList, fmt.Errorf("failed to marshal JSON: %w", err)
		}
		fmt.Println(string(jsonBytes))
	} else if !config.Stats {
		// Print summary for text output (skip if stats mode)
		printCompilationSummary(stats)
	}

	// Save the action cache after all compilations
	if actionCache != nil {
		if err := actionCache.Save(); err != nil {
			compileOrchestratorLog.Printf("Failed to save action cache: %v", err)
			if verbose {
				fmt.Fprintln(os.Stderr, console.FormatWarningMessage(fmt.Sprintf("Failed to save action cache: %v", err)))
			}
		} else {
			compileOrchestratorLog.Print("Action cache saved successfully")
			if verbose {
				fmt.Fprintln(os.Stderr, console.FormatSuccessMessage(fmt.Sprintf("Action cache saved to %s", actionCache.GetCachePath())))
			}
		}
	}

	// Return error if any compilations failed
	if errorCount > 0 {
		return workflowDataList, fmt.Errorf("compilation failed")
	}

	return workflowDataList, nil
}
