package workflow

import (
	"encoding/json"
	"fmt"
	"strings"

	"github.com/githubnext/gh-aw/pkg/constants"
)

func (c *Compiler) generateYAML(data *WorkflowData, markdownPath string) (string, error) {
	// Reset job manager for this compilation
	c.jobManager = NewJobManager()

	// Build all jobs
	if err := c.buildJobs(data, markdownPath); err != nil {
		return "", fmt.Errorf("failed to build jobs: %w", err)
	}

	// Validate job dependencies
	if err := c.jobManager.ValidateDependencies(); err != nil {
		return "", fmt.Errorf("job dependency validation failed: %w", err)
	}

	// Pre-allocate builder capacity based on estimated workflow size
	// Average workflow generates ~200KB, allocate 256KB to minimize reallocations
	var yaml strings.Builder
	yaml.Grow(256 * 1024)

	// Add auto-generated disclaimer
	yaml.WriteString("# This file was automatically generated by gh-aw. DO NOT EDIT.\n")
	yaml.WriteString("# To update this file, edit the corresponding .md file and run:\n")
	yaml.WriteString("#   " + constants.CLIExtensionPrefix + " compile\n")
	yaml.WriteString("# For more information: https://github.com/githubnext/gh-aw/blob/main/.github/instructions/github-agentic-workflows.instructions.md\n")

	// Add description comment if provided
	if data.Description != "" {
		yaml.WriteString("#\n")
		// Split description into lines and prefix each with "# "
		descriptionLines := strings.Split(strings.TrimSpace(data.Description), "\n")
		for _, line := range descriptionLines {
			yaml.WriteString(fmt.Sprintf("# %s\n", strings.TrimSpace(line)))
		}
	}

	// Add source comment if provided
	if data.Source != "" {
		yaml.WriteString("#\n")
		yaml.WriteString(fmt.Sprintf("# Source: %s\n", data.Source))
	}

	// Add manifest of imported/included files if any exist
	if len(data.ImportedFiles) > 0 || len(data.IncludedFiles) > 0 {
		yaml.WriteString("#\n")
		yaml.WriteString("# Resolved workflow manifest:\n")

		if len(data.ImportedFiles) > 0 {
			yaml.WriteString("#   Imports:\n")
			for _, file := range data.ImportedFiles {
				yaml.WriteString(fmt.Sprintf("#     - %s\n", file))
			}
		}

		if len(data.IncludedFiles) > 0 {
			yaml.WriteString("#   Includes:\n")
			for _, file := range data.IncludedFiles {
				yaml.WriteString(fmt.Sprintf("#     - %s\n", file))
			}
		}
	}

	// Add stop-time comment if configured
	if data.StopTime != "" {
		yaml.WriteString("#\n")
		yaml.WriteString(fmt.Sprintf("# Effective stop-time: %s\n", data.StopTime))
	}

	// Add Mermaid graph of job dependencies
	mermaidGraph := c.jobManager.GenerateMermaidGraph()
	if mermaidGraph != "" {
		yaml.WriteString("#\n")
		yaml.WriteString("# Job Dependency Graph:\n")
		// Add each line of the mermaid graph as a comment
		for _, line := range strings.Split(mermaidGraph, "\n") {
			yaml.WriteString(fmt.Sprintf("# %s\n", line))
		}
	}

	yaml.WriteString("\n")

	// Write basic workflow structure
	yaml.WriteString(fmt.Sprintf("name: \"%s\"\n", data.Name))
	yaml.WriteString(data.On + "\n\n")

	// Add permissions if present
	if data.Permissions != "" {
		yaml.WriteString(data.Permissions + "\n\n")
	} else {
		yaml.WriteString("permissions: {}\n\n")
	}

	yaml.WriteString(data.Concurrency + "\n\n")
	yaml.WriteString(data.RunName + "\n\n")

	// Add env section if present
	if data.Env != "" {
		yaml.WriteString(data.Env + "\n\n")
	}

	// Add cache comment if cache configuration was provided
	if data.Cache != "" {
		yaml.WriteString("# Cache configuration from frontmatter was processed and added to the main job steps\n\n")
	}

	// Generate jobs section using JobManager
	yaml.WriteString(c.jobManager.RenderToYAML())

	yamlContent := yaml.String()

	// Collect used action pins from the generated YAML and add them to the header
	usedPins := collectUsedActionPins(yamlContent)
	pinnedActionsComment := generatePinnedActionsComment(usedPins)

	// If we have pinned actions, insert the comment before the workflow name
	if pinnedActionsComment != "" {
		// Find the position after the mermaid graph and before "name:"
		// The yamlContent has the header comments, then a blank line, then "name:"
		namePos := strings.Index(yamlContent, "\nname:")
		if namePos != -1 {
			// Insert the pinned actions comment before "name:"
			yamlContent = yamlContent[:namePos] + pinnedActionsComment + yamlContent[namePos:]
		}
	}

	// If we're in non-cloning trial mode and this workflow has issue triggers,
	// replace github.event.issue.number with inputs.issue_number
	if c.trialMode && c.hasIssueTrigger(data.On) {
		yamlContent = c.replaceIssueNumberReferences(yamlContent)
	}

	return yamlContent, nil
}

func (c *Compiler) generateMainJobSteps(yaml *strings.Builder, data *WorkflowData) {
	// Determine if we need to add a checkout step
	needsCheckout := c.shouldAddCheckoutStep(data)

	// Add checkout step first if needed
	if needsCheckout {
		yaml.WriteString("      - name: Checkout repository\n")
		yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/checkout")))
		// Always add with section for persist-credentials
		yaml.WriteString("        with:\n")
		yaml.WriteString("          persist-credentials: false\n")
		// In trial mode without cloning, checkout the logical repo if specified
		if c.trialMode {
			if c.trialLogicalRepoSlug != "" {
				yaml.WriteString(fmt.Sprintf("          repository: %s\n", c.trialLogicalRepoSlug))
				// trialTargetRepoName := strings.Split(c.trialLogicalRepoSlug, "/")
				// if len(trialTargetRepoName) == 2 {
				// 	yaml.WriteString(fmt.Sprintf("          path: %s\n", trialTargetRepoName[1]))
				// }
			}
			effectiveToken := getEffectiveGitHubToken("", data.GitHubToken)
			yaml.WriteString(fmt.Sprintf("          token: %s\n", effectiveToken))
		}
	}

	// Add automatic runtime setup steps if needed
	// This detects runtimes from custom steps and MCP configs
	// Must be added BEFORE custom steps so the runtimes are available
	// Runtime detection now smartly filters out runtimes that already have setup actions
	runtimeRequirements := DetectRuntimeRequirements(data)
	runtimeSetupSteps := GenerateRuntimeSetupSteps(runtimeRequirements)
	for _, step := range runtimeSetupSteps {
		for _, line := range step {
			yaml.WriteString(line + "\n")
		}
	}

	// Add custom steps if present
	if data.CustomSteps != "" {
		// Remove "steps:" line and adjust indentation
		lines := strings.Split(data.CustomSteps, "\n")
		if len(lines) > 1 {
			for _, line := range lines[1:] {
				// Skip empty lines
				if strings.TrimSpace(line) == "" {
					yaml.WriteString("\n")
					continue
				}

				// Simply add 6 spaces for job context indentation
				yaml.WriteString("      " + line + "\n")
			}
		}
	}

	// Create /tmp/gh-aw/ base directory for all temporary files
	yaml.WriteString("      - name: Create gh-aw temp directory\n")
	yaml.WriteString("        run: |\n")
	WriteShellScriptToYAML(yaml, createGhAwTmpDirScript, "          ")

	// Add cache steps if cache configuration is present
	generateCacheSteps(yaml, data, c.verbose)

	// Add cache-memory steps if cache-memory configuration is present
	generateCacheMemorySteps(yaml, data)

	// Configure git credentials for agentic workflows
	gitConfigSteps := c.generateGitConfigurationSteps()
	for _, line := range gitConfigSteps {
		yaml.WriteString(line)
	}

	// Add step to checkout PR branch if the event is pull_request
	c.generatePRReadyForReviewCheckout(yaml, data)

	// Add Node.js setup if the engine requires it and it's not already set up in custom steps
	engine, err := c.getAgenticEngine(data.AI)

	if err != nil {
		return
	}

	// Add engine-specific installation steps (includes Node.js setup for npm-based engines)
	installSteps := engine.GetInstallationSteps(data)
	for _, step := range installSteps {
		for _, line := range step {
			yaml.WriteString(line + "\n")
		}
	}

	// GH_AW_SAFE_OUTPUTS is now set at job level, no setup step needed

	// Add MCP setup
	c.generateMCPSetup(yaml, data.Tools, engine, data)

	// Stop-time safety checks are now handled by a dedicated job (stop_time_check)
	// No longer generated in the main job steps

	// Add prompt creation step
	c.generatePrompt(yaml, data)

	// Upload prompt to artifact
	c.generateUploadPrompt(yaml)

	logFile := "agent-stdio"
	logFileFull := "/tmp/gh-aw/agent-stdio.log"

	// Generate aw_info.json with agentic run metadata
	c.generateCreateAwInfo(yaml, data, engine)

	// Upload info to artifact
	c.generateUploadAwInfo(yaml)

	// Add AI execution step using the agentic engine
	c.generateEngineExecutionSteps(yaml, data, engine, logFileFull)

	// Mark that we've completed agent execution - step order validation starts from here
	c.stepOrderTracker.MarkAgentExecutionComplete()

	// Add secret redaction step BEFORE any artifact uploads
	// This ensures all artifacts are scanned for secrets before being uploaded
	c.generateSecretRedactionStep(yaml, yaml.String(), data)

	// Add output collection step only if safe-outputs feature is used (GH_AW_SAFE_OUTPUTS functionality)
	if data.SafeOutputs != nil {
		c.generateOutputCollectionStep(yaml, data)
	}

	// Add engine-declared output files collection (if any)
	if len(engine.GetDeclaredOutputFiles()) > 0 {
		c.generateEngineOutputCollection(yaml, engine)
	}

	// Extract and upload squid access logs (if any proxy tools were used)
	c.generateExtractAccessLogs(yaml, data.Tools)
	c.generateUploadAccessLogs(yaml, data.Tools)

	// upload MCP logs (if any MCP tools were used)
	c.generateUploadMCPLogs(yaml)

	// parse agent logs for GITHUB_STEP_SUMMARY
	c.generateLogParsing(yaml, engine)

	// Add Squid logs collection and upload steps for Copilot engine
	if copilotEngine, ok := engine.(*CopilotEngine); ok {
		squidSteps := copilotEngine.GetSquidLogsSteps(data)
		for _, step := range squidSteps {
			for _, line := range step {
				yaml.WriteString(line + "\n")
			}
		}
	}

	// upload agent logs
	var _ string = logFile
	c.generateUploadAgentLogs(yaml, logFileFull)

	// Add post-execution cleanup step for Copilot engine
	if copilotEngine, ok := engine.(*CopilotEngine); ok {
		cleanupStep := copilotEngine.GetCleanupStep(data)
		for _, line := range cleanupStep {
			yaml.WriteString(line + "\n")
		}
	}

	// upload assets if upload-asset is configured
	if data.SafeOutputs != nil && data.SafeOutputs.UploadAssets != nil {
		c.generateUploadAssets(yaml)
	}

	// Add error validation for AI execution logs
	c.generateErrorValidation(yaml, engine, data)

	// Add git patch generation step only if safe-outputs create-pull-request feature is used
	if data.SafeOutputs != nil && (data.SafeOutputs.CreatePullRequests != nil || data.SafeOutputs.PushToPullRequestBranch != nil) {
		c.generateGitPatchStep(yaml)
	}

	// Add post-steps (if any) after AI execution
	c.generatePostSteps(yaml, data)

	// Validate step ordering - this is a compiler check to ensure security
	if err := c.stepOrderTracker.ValidateStepOrdering(); err != nil {
		// This is a compiler bug if validation fails
		panic(err)
	}
}

func (c *Compiler) generateUploadAgentLogs(yaml *strings.Builder, logFileFull string) {
	// Record artifact upload for validation
	c.stepOrderTracker.RecordArtifactUpload("Upload Agent Stdio", []string{logFileFull})

	yaml.WriteString("      - name: Upload Agent Stdio\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/upload-artifact")))
	yaml.WriteString("        with:\n")
	yaml.WriteString("          name: agent-stdio.log\n")
	fmt.Fprintf(yaml, "          path: %s\n", logFileFull)
	yaml.WriteString("          if-no-files-found: warn\n")
}

func (c *Compiler) generateUploadAssets(yaml *strings.Builder) {
	// Record artifact upload for validation
	c.stepOrderTracker.RecordArtifactUpload("Upload safe outputs assets", []string{"/tmp/gh-aw/safeoutputs/assets/"})

	yaml.WriteString("      - name: Upload safe outputs assets\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/upload-artifact")))
	yaml.WriteString("        with:\n")
	yaml.WriteString("          name: safe-outputs-assets\n")
	yaml.WriteString("          path: /tmp/gh-aw/safeoutputs/assets/\n")
	yaml.WriteString("          if-no-files-found: ignore\n")
}

func (c *Compiler) generateLogParsing(yaml *strings.Builder, engine CodingAgentEngine) {
	parserScriptName := engine.GetLogParserScriptId()
	if parserScriptName == "" {
		// Skip log parsing if engine doesn't provide a parser
		return
	}

	logParserScript := GetLogParserScript(parserScriptName)
	if logParserScript == "" {
		// Skip if parser script not found
		return
	}

	// Get the log file path for parsing (may be different from stdout/stderr log)
	logFileForParsing := engine.GetLogFileForParsing()

	yaml.WriteString("      - name: Parse agent logs for step summary\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/github-script")))
	yaml.WriteString("        env:\n")
	fmt.Fprintf(yaml, "          GH_AW_AGENT_OUTPUT: %s\n", logFileForParsing)
	yaml.WriteString("        with:\n")
	yaml.WriteString("          script: |\n")

	// Inline the JavaScript code with proper indentation
	steps := FormatJavaScriptForYAML(logParserScript)
	for _, step := range steps {
		yaml.WriteString(step)
	}
}

// convertGoPatternToJavaScript converts a Go regex pattern to JavaScript-compatible format
// This removes Go's (?i) inline case-insensitive flag since JavaScript doesn't support it

func (c *Compiler) convertGoPatternToJavaScript(goPattern string) string {
	// Convert (?i) inline case-insensitive flag by removing it
	// JavaScript RegExp will be created with "gi" flags to handle case insensitivity
	if strings.HasPrefix(goPattern, "(?i)") {
		return goPattern[4:] // Remove (?i) prefix
	}
	return goPattern
}

// convertErrorPatternsToJavaScript converts a slice of Go error patterns to JavaScript-compatible patterns
func (c *Compiler) convertErrorPatternsToJavaScript(goPatterns []ErrorPattern) []ErrorPattern {
	jsPatterns := make([]ErrorPattern, len(goPatterns))
	for i, pattern := range goPatterns {
		jsPatterns[i] = ErrorPattern{
			Pattern:      c.convertGoPatternToJavaScript(pattern.Pattern),
			LevelGroup:   pattern.LevelGroup,
			MessageGroup: pattern.MessageGroup,
			Description:  pattern.Description,
		}
	}
	return jsPatterns
}

func (c *Compiler) generateErrorValidation(yaml *strings.Builder, engine CodingAgentEngine, data *WorkflowData) {
	// Concatenate engine error patterns and configured error patterns
	var errorPatterns []ErrorPattern

	// Add engine-defined patterns
	enginePatterns := engine.GetErrorPatterns()
	errorPatterns = append(errorPatterns, enginePatterns...)

	// Add user-configured patterns from engine config
	if data.EngineConfig != nil && len(data.EngineConfig.ErrorPatterns) > 0 {
		errorPatterns = append(errorPatterns, data.EngineConfig.ErrorPatterns...)
	}

	// Skip if no error patterns are available
	if len(errorPatterns) == 0 {
		return
	}

	// Convert Go regex patterns to JavaScript-compatible patterns
	jsCompatiblePatterns := c.convertErrorPatternsToJavaScript(errorPatterns)

	errorValidationScript := validateErrorsScript
	if errorValidationScript == "" {
		// Skip if validation script not found
		return
	}

	// Get the log file path for validation (may be different from stdout/stderr log)
	logFileForValidation := engine.GetLogFileForParsing()

	yaml.WriteString("      - name: Validate agent logs for errors\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/github-script")))
	yaml.WriteString("        env:\n")
	fmt.Fprintf(yaml, "          GH_AW_AGENT_OUTPUT: %s\n", logFileForValidation)

	// Add JavaScript-compatible error patterns as a single JSON array
	patternsJSON, err := json.Marshal(jsCompatiblePatterns)
	if err != nil {
		// Skip if patterns can't be marshaled
		return
	}
	fmt.Fprintf(yaml, "          GH_AW_ERROR_PATTERNS: %q\n", string(patternsJSON))

	yaml.WriteString("        with:\n")
	yaml.WriteString("          script: |\n")

	// Inline the JavaScript code with proper indentation
	steps := FormatJavaScriptForYAML(errorValidationScript)
	for _, step := range steps {
		yaml.WriteString(step)
	}
}

func (c *Compiler) generateUploadAwInfo(yaml *strings.Builder) {
	// Record artifact upload for validation
	c.stepOrderTracker.RecordArtifactUpload("Upload agentic run info", []string{"/tmp/gh-aw/aw_info.json"})

	yaml.WriteString("      - name: Upload agentic run info\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/upload-artifact")))
	yaml.WriteString("        with:\n")
	yaml.WriteString("          name: aw_info.json\n")
	yaml.WriteString("          path: /tmp/gh-aw/aw_info.json\n")
	yaml.WriteString("          if-no-files-found: warn\n")
}

func (c *Compiler) generateUploadPrompt(yaml *strings.Builder) {
	// Record artifact upload for validation
	c.stepOrderTracker.RecordArtifactUpload("Upload prompt", []string{"/tmp/gh-aw/aw-prompts/prompt.txt"})

	yaml.WriteString("      - name: Upload prompt\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/upload-artifact")))
	yaml.WriteString("        with:\n")
	yaml.WriteString("          name: prompt.txt\n")
	yaml.WriteString("          path: /tmp/gh-aw/aw-prompts/prompt.txt\n")
	yaml.WriteString("          if-no-files-found: warn\n")
}

func (c *Compiler) generateExtractAccessLogs(yaml *strings.Builder, tools map[string]any) {
	// No proxy tools anymore - network filtering is handled at workflow level
}

func (c *Compiler) generateUploadAccessLogs(yaml *strings.Builder, tools map[string]any) {
	// No proxy tools anymore - network filtering is handled at workflow level
}

func (c *Compiler) generateUploadMCPLogs(yaml *strings.Builder) {
	// Record artifact upload for validation
	c.stepOrderTracker.RecordArtifactUpload("Upload MCP logs", []string{"/tmp/gh-aw/mcp-logs/"})

	yaml.WriteString("      - name: Upload MCP logs\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/upload-artifact")))
	yaml.WriteString("        with:\n")
	yaml.WriteString("          name: mcp-logs\n")
	yaml.WriteString("          path: /tmp/gh-aw/mcp-logs/\n")
	yaml.WriteString("          if-no-files-found: ignore\n")
}

func splitContentIntoChunks(content string) []string {
	const maxChunkSize = 20900        // 21000 - 100 character buffer
	const indentSpaces = "          " // 10 spaces added to each line

	lines := strings.Split(content, "\n")
	var chunks []string
	var currentChunk []string
	currentSize := 0

	for _, line := range lines {
		lineSize := len(indentSpaces) + len(line) + 1 // +1 for newline

		// If adding this line would exceed the limit, start a new chunk
		if currentSize+lineSize > maxChunkSize && len(currentChunk) > 0 {
			chunks = append(chunks, strings.Join(currentChunk, "\n"))
			currentChunk = []string{line}
			currentSize = lineSize
		} else {
			currentChunk = append(currentChunk, line)
			currentSize += lineSize
		}
	}

	// Add the last chunk if there's content
	if len(currentChunk) > 0 {
		chunks = append(chunks, strings.Join(currentChunk, "\n"))
	}

	return chunks
}

func (c *Compiler) generatePrompt(yaml *strings.Builder, data *WorkflowData) {
	// Clean the markdown content
	cleanedMarkdownContent := removeXMLComments(data.MarkdownContent)

	// Extract expressions and create environment variable mappings for security
	extractor := NewExpressionExtractor()
	expressionMappings, err := extractor.ExtractExpressions(cleanedMarkdownContent)
	if err != nil {
		// Log error but continue - this is a compiler step, we shouldn't fail
		// The original expressions will be used if extraction fails
		expressionMappings = nil
	}

	// Replace expressions with environment variable references
	if len(expressionMappings) > 0 {
		cleanedMarkdownContent = extractor.ReplaceExpressionsWithEnvVars(cleanedMarkdownContent)
	}

	// Wrap GitHub expressions in template conditionals
	cleanedMarkdownContent = wrapExpressionsInTemplateConditionals(cleanedMarkdownContent)

	// Split content into manageable chunks
	chunks := splitContentIntoChunks(cleanedMarkdownContent)

	// Create the initial prompt file step
	yaml.WriteString("      - name: Create prompt\n")
	yaml.WriteString("        env:\n")
	yaml.WriteString("          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt\n")
	if data.SafeOutputs != nil {
		yaml.WriteString("          GH_AW_SAFE_OUTPUTS: ${{ env.GH_AW_SAFE_OUTPUTS }}\n")
	}

	// Add environment variables for extracted expressions
	for _, mapping := range expressionMappings {
		// Write the environment variable with the original GitHub expression
		fmt.Fprintf(yaml, "          %s: ${{ %s }}\n", mapping.EnvVar, mapping.Content)
	}

	yaml.WriteString("        run: |\n")
	WriteShellScriptToYAML(yaml, createPromptFirstScript, "          ")

	if len(chunks) > 0 {
		yaml.WriteString("          cat > $GH_AW_PROMPT << 'PROMPT_EOF'\n")
		// Pre-allocate buffer to avoid repeated allocations
		lines := strings.Split(chunks[0], "\n")
		for _, line := range lines {
			yaml.WriteString("          ")
			yaml.WriteString(line)
			yaml.WriteByte('\n')
		}
		yaml.WriteString("          PROMPT_EOF\n")
	} else {
		yaml.WriteString("          touch $GH_AW_PROMPT\n")
	}

	// Create additional steps for remaining chunks
	for i, chunk := range chunks[1:] {
		stepNum := i + 2
		yaml.WriteString(fmt.Sprintf("      - name: Append prompt (part %d)\n", stepNum))
		yaml.WriteString("        env:\n")
		yaml.WriteString("          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt\n")
		yaml.WriteString("        run: |\n")
		yaml.WriteString("          cat >> $GH_AW_PROMPT << 'PROMPT_EOF'\n")
		// Avoid string concatenation in loop - write components separately
		lines := strings.Split(chunk, "\n")
		for _, line := range lines {
			yaml.WriteString("          ")
			yaml.WriteString(line)
			yaml.WriteByte('\n')
		}
		yaml.WriteString("          PROMPT_EOF\n")
	}

	// Add XPIA security prompt as separate step if enabled (before other prompts)
	c.generateXPIAPromptStep(yaml, data)

	// Add temporary folder usage instructions
	c.generateTempFolderPromptStep(yaml)

	// Add playwright output directory instructions if playwright tool is enabled
	c.generatePlaywrightPromptStep(yaml, data)

	// Add edit tool accessibility instructions if edit tool is enabled
	c.generateEditToolPromptStep(yaml, data)

	// trialTargetRepoName := strings.Split(c.trialLogicalRepoSlug, "/")
	// if len(trialTargetRepoName) == 2 {
	// 	yaml.WriteString(fmt.Sprintf("          path: %s\n", trialTargetRepoName[1]))
	// }
	// If trialling, generate a step to append a note about it in the prompt
	if c.trialMode {
		yaml.WriteString("      - name: Append trial mode note to prompt\n")
		yaml.WriteString("        env:\n")
		yaml.WriteString("          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt\n")
		yaml.WriteString("        run: |\n")
		yaml.WriteString("          cat >> $GH_AW_PROMPT << 'PROMPT_EOF'\n")
		yaml.WriteString("          ## Note\n")
		yaml.WriteString(fmt.Sprintf("          This workflow is running in directory $GITHUB_WORKSPACE, but that directory actually contains the contents of the repository '%s'.\n", c.trialLogicalRepoSlug))
		yaml.WriteString("          PROMPT_EOF\n")
	}

	// Add cache memory prompt as separate step if enabled
	c.generateCacheMemoryPromptStep(yaml, data.CacheMemoryConfig)

	// Add safe outputs prompt as separate step if enabled
	c.generateSafeOutputsPromptStep(yaml, data.SafeOutputs)

	// Add GitHub context prompt as separate step if GitHub tool is enabled
	c.generateGitHubContextPromptStep(yaml, data)

	// Add PR context prompt as separate step if enabled
	c.generatePRContextPromptStep(yaml, data)

	// Add template rendering step if conditional patterns are detected
	c.generateTemplateRenderingStep(yaml, data)

	// Print prompt to step summary (merged into prompt generation)
	yaml.WriteString("      - name: Print prompt to step summary\n")
	yaml.WriteString("        env:\n")
	yaml.WriteString("          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt\n")
	yaml.WriteString("        run: |\n")
	WriteShellScriptToYAML(yaml, printPromptSummaryScript, "          ")
}

func (c *Compiler) generateCacheMemoryPromptStep(yaml *strings.Builder, config *CacheMemoryConfig) {
	if config == nil || len(config.Caches) == 0 {
		return
	}

	appendPromptStepWithHeredoc(yaml,
		"Append cache memory instructions to prompt",
		func(y *strings.Builder) {
			generateCacheMemoryPromptSection(y, config)
		})
}

func (c *Compiler) generateSafeOutputsPromptStep(yaml *strings.Builder, safeOutputs *SafeOutputsConfig) {
	if safeOutputs == nil {
		return
	}

	appendPromptStepWithHeredoc(yaml,
		"Append safe outputs instructions to prompt",
		func(y *strings.Builder) {
			generateSafeOutputsPromptSection(y, safeOutputs)
		})
}

func (c *Compiler) generatePostSteps(yaml *strings.Builder, data *WorkflowData) {
	if data.PostSteps != "" {
		// Remove "post-steps:" line and adjust indentation, similar to CustomSteps processing
		lines := strings.Split(data.PostSteps, "\n")
		if len(lines) > 1 {
			for _, line := range lines[1:] {
				// Trim trailing whitespace
				trimmed := strings.TrimRight(line, " ")
				// Skip empty lines
				if strings.TrimSpace(trimmed) == "" {
					yaml.WriteString("\n")
					continue
				}
				// Steps need 6-space indentation (      - name:)
				// Nested properties need 8-space indentation (        run:)
				if strings.HasPrefix(line, "  ") {
					yaml.WriteString("        " + line[2:] + "\n")
				} else {
					yaml.WriteString("      " + line + "\n")
				}
			}
		}
	}
}

func (c *Compiler) convertStepToYAML(stepMap map[string]any) (string, error) {
	return ConvertStepToYAML(stepMap)
}

func (c *Compiler) generateEngineExecutionSteps(yaml *strings.Builder, data *WorkflowData, engine CodingAgentEngine, logFile string) {

	steps := engine.GetExecutionSteps(data, logFile)

	for _, step := range steps {
		for _, line := range step {
			yaml.WriteString(line + "\n")
		}
	}
}

// getInstallationVersion returns the version that will be installed for the given engine.
// This matches the logic in BuildStandardNpmEngineInstallSteps.
func getInstallationVersion(data *WorkflowData, engine CodingAgentEngine) string {
	// If version is specified in engine config, use it
	if data.EngineConfig != nil && data.EngineConfig.Version != "" {
		return data.EngineConfig.Version
	}

	// Otherwise, use the default version for the engine
	switch engine.GetID() {
	case "copilot":
		return constants.DefaultCopilotVersion
	case "claude":
		return constants.DefaultClaudeCodeVersion
	case "codex":
		return constants.DefaultCodexVersion
	default:
		// Custom or unknown engines don't have a default version
		return ""
	}
}

func (c *Compiler) generateCreateAwInfo(yaml *strings.Builder, data *WorkflowData, engine CodingAgentEngine) {
	yaml.WriteString("      - name: Generate agentic run info\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/github-script")))
	yaml.WriteString("        with:\n")
	yaml.WriteString("          script: |\n")
	yaml.WriteString("            const fs = require('fs');\n")
	yaml.WriteString("            \n")
	yaml.WriteString("            const awInfo = {\n")

	// Engine ID (prefer EngineConfig.ID, fallback to AI field for backwards compatibility)
	engineID := engine.GetID()
	if data.EngineConfig != nil && data.EngineConfig.ID != "" {
		engineID = data.EngineConfig.ID
	} else if data.AI != "" {
		engineID = data.AI
	}
	fmt.Fprintf(yaml, "              engine_id: \"%s\",\n", engineID)

	// Engine display name
	fmt.Fprintf(yaml, "              engine_name: \"%s\",\n", engine.GetDisplayName())

	// Model information
	model := ""
	if data.EngineConfig != nil && data.EngineConfig.Model != "" {
		model = data.EngineConfig.Model
	}
	fmt.Fprintf(yaml, "              model: \"%s\",\n", model)

	// Version information (from engine config, kept for backwards compatibility)
	version := ""
	if data.EngineConfig != nil && data.EngineConfig.Version != "" {
		version = data.EngineConfig.Version
	}
	fmt.Fprintf(yaml, "              version: \"%s\",\n", version)

	// Agent version - use the actual installation version (includes defaults)
	// This matches what BuildStandardNpmEngineInstallSteps uses
	agentVersion := getInstallationVersion(data, engine)
	fmt.Fprintf(yaml, "              agent_version: \"%s\",\n", agentVersion)

	// Workflow information
	fmt.Fprintf(yaml, "              workflow_name: \"%s\",\n", data.Name)
	fmt.Fprintf(yaml, "              experimental: %t,\n", engine.IsExperimental())
	fmt.Fprintf(yaml, "              supports_tools_allowlist: %t,\n", engine.SupportsToolsAllowlist())
	fmt.Fprintf(yaml, "              supports_http_transport: %t,\n", engine.SupportsHTTPTransport())

	// Run metadata
	yaml.WriteString("              run_id: context.runId,\n")
	yaml.WriteString("              run_number: context.runNumber,\n")
	yaml.WriteString("              run_attempt: process.env.GITHUB_RUN_ATTEMPT,\n")
	yaml.WriteString("              repository: context.repo.owner + '/' + context.repo.repo,\n")
	yaml.WriteString("              ref: context.ref,\n")
	yaml.WriteString("              sha: context.sha,\n")
	yaml.WriteString("              actor: context.actor,\n")
	yaml.WriteString("              event_name: context.eventName,\n")

	// Add staged value from safe-outputs configuration
	stagedValue := "false"
	if data.SafeOutputs != nil && data.SafeOutputs.Staged {
		stagedValue = "true"
	}
	fmt.Fprintf(yaml, "              staged: %s,\n", stagedValue)

	// Add steps object with firewall information
	yaml.WriteString("              steps: {\n")

	// Determine firewall type
	firewallType := ""
	if isFirewallEnabled(data) {
		firewallType = "squid"
	}
	fmt.Fprintf(yaml, "                firewall: \"%s\"\n", firewallType)

	yaml.WriteString("              },\n")

	yaml.WriteString("              created_at: new Date().toISOString()\n")

	yaml.WriteString("            };\n")
	yaml.WriteString("            \n")
	yaml.WriteString("            // Write to /tmp/gh-aw directory to avoid inclusion in PR\n")
	yaml.WriteString("            const tmpPath = '/tmp/gh-aw/aw_info.json';\n")
	yaml.WriteString("            fs.writeFileSync(tmpPath, JSON.stringify(awInfo, null, 2));\n")
	yaml.WriteString("            console.log('Generated aw_info.json at:', tmpPath);\n")
	yaml.WriteString("            console.log(JSON.stringify(awInfo, null, 2));\n")
}

func (c *Compiler) generateOutputCollectionStep(yaml *strings.Builder, data *WorkflowData) {
	// Record artifact upload for validation
	c.stepOrderTracker.RecordArtifactUpload("Upload Safe Outputs", []string{"${{ env.GH_AW_SAFE_OUTPUTS }}"})

	yaml.WriteString("      - name: Upload Safe Outputs\n")
	yaml.WriteString("        if: always()\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/upload-artifact")))
	yaml.WriteString("        with:\n")
	fmt.Fprintf(yaml, "          name: %s\n", constants.SafeOutputArtifactName)
	yaml.WriteString("          path: ${{ env.GH_AW_SAFE_OUTPUTS }}\n")
	yaml.WriteString("          if-no-files-found: warn\n")

	yaml.WriteString("      - name: Ingest agent output\n")
	yaml.WriteString("        id: collect_output\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/github-script")))

	// Add environment variables for JSONL validation
	yaml.WriteString("        env:\n")
	yaml.WriteString("          GH_AW_SAFE_OUTPUTS: ${{ env.GH_AW_SAFE_OUTPUTS }}\n")

	// Pass the safe-outputs configuration for validation
	safeOutputConfig := generateSafeOutputsConfig(data)
	if safeOutputConfig != "" {
		fmt.Fprintf(yaml, "          GH_AW_SAFE_OUTPUTS_CONFIG: %q\n", safeOutputConfig)
	}

	// Add allowed domains configuration for sanitization
	// Use manually configured domains if available, otherwise compute from network configuration
	var domainsStr string
	if data.SafeOutputs != nil && len(data.SafeOutputs.AllowedDomains) > 0 {
		// Use manually configured allowed domains
		domainsStr = strings.Join(data.SafeOutputs.AllowedDomains, ",")
	} else {
		// Fall back to computing from network configuration (same as firewall)
		domainsStr = c.computeAllowedDomainsForSanitization(data)
	}
	if domainsStr != "" {
		fmt.Fprintf(yaml, "          GH_AW_ALLOWED_DOMAINS: %q\n", domainsStr)
	}

	// Add command name for command trigger prevention in safe outputs
	if data.Command != "" {
		fmt.Fprintf(yaml, "          GH_AW_COMMAND: %s\n", data.Command)
	}

	yaml.WriteString("        with:\n")
	yaml.WriteString("          script: |\n")

	// Add each line of the script with proper indentation
	WriteJavaScriptToYAML(yaml, getCollectJSONLOutputScript())

	// Record artifact upload for validation
	c.stepOrderTracker.RecordArtifactUpload("Upload sanitized agent output", []string{"${{ env.GH_AW_AGENT_OUTPUT }}"})

	yaml.WriteString("      - name: Upload sanitized agent output\n")
	yaml.WriteString("        if: always() && env.GH_AW_AGENT_OUTPUT\n")
	yaml.WriteString(fmt.Sprintf("        uses: %s\n", GetActionPin("actions/upload-artifact")))
	yaml.WriteString("        with:\n")
	yaml.WriteString("          name: agent_output.json\n")
	yaml.WriteString("          path: ${{ env.GH_AW_AGENT_OUTPUT }}\n")
	yaml.WriteString("          if-no-files-found: warn\n")

}

// collectUsedActionPins scans the YAML content for uses: directives and returns a map of used action pins
// The returned map keys are action repository names, and values are ActionPin structs
func collectUsedActionPins(yamlContent string) map[string]ActionPin {
	usedPins := make(map[string]ActionPin)

	// Scan each line for "uses:" directives
	lines := strings.Split(yamlContent, "\n")
	for _, line := range lines {
		trimmed := strings.TrimSpace(line)

		// Match both "uses:" and "- uses:" (step format)
		var usesValue string
		if strings.HasPrefix(trimmed, "uses:") {
			// Format: "uses: owner/repo@sha"
			parts := strings.SplitN(trimmed, ":", 2)
			if len(parts) == 2 {
				usesValue = strings.TrimSpace(parts[1])
			}
		} else if strings.HasPrefix(trimmed, "- uses:") {
			// Format: "- uses: owner/repo@sha"
			parts := strings.SplitN(trimmed, ":", 2)
			if len(parts) == 2 {
				usesValue = strings.TrimSpace(parts[1])
			}
		}

		if usesValue == "" {
			continue
		}

		// Extract the repository part (before @)
		actionRepo := extractActionRepo(usesValue)
		if actionRepo == "" {
			continue
		}

		// Check if this action is in our pinned actions
		if pin, exists := GetActionPinByRepo(actionRepo); exists {
			usedPins[actionRepo] = pin
		}
	}

	return usedPins
}

// generatePinnedActionsComment generates a comment section listing all pinned actions used in the workflow
// The comment includes the repository, version tag, SHA, and GitHub URL for each action
func generatePinnedActionsComment(usedPins map[string]ActionPin) string {
	if len(usedPins) == 0 {
		return ""
	}

	// Sort the pins by repository name for consistent output
	sortedRepos := make([]string, 0, len(usedPins))
	for repo := range usedPins {
		sortedRepos = append(sortedRepos, repo)
	}

	// Simple bubble sort for consistency
	for i := 0; i < len(sortedRepos); i++ {
		for j := i + 1; j < len(sortedRepos); j++ {
			if sortedRepos[i] > sortedRepos[j] {
				sortedRepos[i], sortedRepos[j] = sortedRepos[j], sortedRepos[i]
			}
		}
	}

	var comment strings.Builder
	comment.WriteString("#\n")
	comment.WriteString("# Pinned GitHub Actions:\n")

	for _, repo := range sortedRepos {
		pin := usedPins[repo]
		// Generate the GitHub URL to the specific commit
		// For "actions/checkout" -> "https://github.com/actions/checkout/commit/08c6903..."
		// For "github/codeql-action/upload-sarif" -> "https://github.com/github/codeql-action/commit/562257d..."

		// Extract the base repository (owner/repo) from potentially nested paths
		var baseRepo string
		repoParts := strings.Split(repo, "/")
		if len(repoParts) >= 2 {
			baseRepo = repoParts[0] + "/" + repoParts[1]
		} else {
			baseRepo = repo
		}

		githubURL := fmt.Sprintf("https://github.com/%s/commit/%s", baseRepo, pin.SHA)

		comment.WriteString(fmt.Sprintf("#   - %s@%s (%s)\n", repo, pin.Version, pin.SHA))
		comment.WriteString(fmt.Sprintf("#     %s\n", githubURL))
	}

	return comment.String()
}
