#!/usr/bin/env python3
"""
Network permissions validator for Claude Code engine.
Generated by gh-aw from workflow-level network configuration.
"""

import json
import sys
import urllib.parse
import re

# Domain allow-list (populated during generation)
# JSON string is safely parsed using json.loads() to eliminate quoting vulnerabilities
ALLOWED_DOMAINS = json.loads('''["api.snapcraft.io","archive.ubuntu.com","azure.archive.ubuntu.com","crl.geotrust.com","crl.globalsign.com","crl.identrust.com","crl.sectigo.com","crl.thawte.com","crl.usertrust.com","crl.verisign.com","crl3.digicert.com","crl4.digicert.com","crls.ssl.com","json-schema.org","json.schemastore.org","keyserver.ubuntu.com","ocsp.digicert.com","ocsp.geotrust.com","ocsp.globalsign.com","ocsp.identrust.com","ocsp.sectigo.com","ocsp.ssl.com","ocsp.thawte.com","ocsp.usertrust.com","ocsp.verisign.com","packagecloud.io","packages.cloud.google.com","packages.microsoft.com","ppa.launchpad.net","s.symcb.com","s.symcd.com","security.ubuntu.com","ts-crl.ws.symantec.com","ts-ocsp.ws.symantec.com"]''')

def extract_domain(url_or_query):
    """Extract domain from URL or search query."""
    if not url_or_query:
        return None
    
    if url_or_query.startswith(('http://', 'https://')):
        return urllib.parse.urlparse(url_or_query).netloc.lower()
    
    # Check for domain patterns in search queries
    match = re.search(r'site:([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', url_or_query)
    if match:
        return match.group(1).lower()
    
    return None

def is_domain_allowed(domain):
    """Check if domain is allowed."""
    if not domain:
        # If no domain detected, allow only if not under deny-all policy
        return bool(ALLOWED_DOMAINS)  # False if empty list (deny-all), True if has domains
    
    # Empty allowed domains means deny all
    if not ALLOWED_DOMAINS:
        return False
    
    for pattern in ALLOWED_DOMAINS:
        regex = pattern.replace('.', r'\.').replace('*', '.*')
        if re.match(f'^{regex}$', domain):
            return True
    return False

# Main logic
try:
    data = json.load(sys.stdin)
    tool_name = data.get('tool_name', '')
    tool_input = data.get('tool_input', {})
    
    if tool_name not in ['WebFetch', 'WebSearch']:
        sys.exit(0)  # Allow other tools
    
    target = tool_input.get('url') or tool_input.get('query', '')
    domain = extract_domain(target)
    
    # For WebSearch, apply domain restrictions consistently
    # If no domain detected in search query, check if restrictions are in place
    if tool_name == 'WebSearch' and not domain:
        # Since this hook is only generated when network permissions are configured,
        # empty ALLOWED_DOMAINS means deny-all policy
        if not ALLOWED_DOMAINS:  # Empty list means deny all
            print(f"Network access blocked: deny-all policy in effect", file=sys.stderr)
            print(f"No domains are allowed for WebSearch", file=sys.stderr)
            sys.exit(2)  # Block under deny-all policy
        else:
            print(f"Network access blocked for web-search: no specific domain detected", file=sys.stderr)
            print(f"Allowed domains: {', '.join(ALLOWED_DOMAINS)}", file=sys.stderr)
            sys.exit(2)  # Block general searches when domain allowlist is configured
    
    if not is_domain_allowed(domain):
        print(f"Network access blocked for domain: {domain}", file=sys.stderr)
        print(f"Allowed domains: {', '.join(ALLOWED_DOMAINS)}", file=sys.stderr)
        sys.exit(2)  # Block with feedback to Claude
    
    sys.exit(0)  # Allow
    
except Exception as e:
    print(f"Network validation error: {e}", file=sys.stderr)
    sys.exit(2)  # Block on errors

