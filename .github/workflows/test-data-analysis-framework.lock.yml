#
#    ___                   _   _      
#   / _ \                 | | (_)     
#  | |_| | __ _  ___ _ __ | |_ _  ___ 
#  |  _  |/ _` |/ _ \ '_ \| __| |/ __|
#  | | | | (_| |  __/ | | | |_| | (__ 
#  \_| |_/\__, |\___|_| |_|\__|_|\___|
#          __/ |
#  _    _ |___/ 
# | |  | |                / _| |
# | |  | | ___ _ __ _  __| |_| | _____      ____
# | |/\| |/ _ \ '__| |/ /|  _| |/ _ \ \ /\ / / ___|
# \  /\  / (_) | | | | ( | | | | (_) \ V  V /\__ \
#  \/  \/ \___/|_| |_|\_\|_| |_|\___/ \_/\_/ |___/
#
# This file was automatically generated by gh-aw. DO NOT EDIT.
#
# To update this file, edit the corresponding .md file and run:
#   gh aw compile
# For more information: https://github.com/githubnext/gh-aw/blob/main/.github/aw/github-agentic-workflows.md
#
# Test workflow to validate the GitHub Data Analysis Framework
#
# Resolved workflow manifest:
#   Imports:
#     - shared/github-data-analysis-framework.md

name: "Test GitHub Data Analysis Framework"
"on": workflow_dispatch

permissions: {}

concurrency:
  group: "gh-aw-${{ github.workflow }}"

run-name: "Test GitHub Data Analysis Framework"

jobs:
  activation:
    needs: pre_activation
    if: needs.pre_activation.outputs.activated == 'true'
    runs-on: ubuntu-slim
    permissions:
      contents: read
    outputs:
      comment_id: ""
      comment_repo: ""
    steps:
      - name: Checkout actions folder
        uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1
        with:
          sparse-checkout: |
            actions
          persist-credentials: false
      - name: Setup Scripts
        uses: ./actions/setup
        with:
          destination: /opt/gh-aw/actions
      - name: Check workflow file timestamps
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        env:
          GH_AW_WORKFLOW_FILE: "test-data-analysis-framework.lock.yml"
        with:
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/check_workflow_timestamp_api.cjs');
            await main();

  agent:
    needs: activation
    runs-on: ubuntu-latest
    permissions:
      contents: read
    concurrency:
      group: "gh-aw-copilot-${{ github.workflow }}"
    outputs:
      model: ${{ steps.generate_aw_info.outputs.model }}
    steps:
      - name: Checkout actions folder
        uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1
        with:
          sparse-checkout: |
            actions
          persist-credentials: false
      - name: Setup Scripts
        uses: ./actions/setup
        with:
          destination: /opt/gh-aw/actions
      - name: Checkout repository
        uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1
        with:
          persist-credentials: false
      - name: Create gh-aw temp directory
        run: bash /opt/gh-aw/actions/create_gh_aw_tmp_dir.sh
      - name: Setup analysis environment
        run: "# Create structured directories for data analysis\nmkdir -p /tmp/gh-aw/analysis/{data,historical,output}\nmkdir -p /tmp/gh-aw/repo-memory/default/metrics/daily\necho \"Analysis environment ready\"\necho \"Current run: $(date -u +%Y-%m-%dT%H:%M:%SZ)\"\n"
      - name: Load historical context
        run: "# Load last 30 days of historical data for trend analysis\nHISTORY_DIR=\"/tmp/gh-aw/repo-memory/default/metrics/daily\"\nif [ -d \"$HISTORY_DIR\" ]; then\n  # Copy last 30 days of data\n  find \"$HISTORY_DIR\" -name \"*.json\" -mtime -30 \\\n    -exec cp {} /tmp/gh-aw/analysis/historical/ \\; 2>/dev/null || true\n  \n  HIST_COUNT=$(ls -1 /tmp/gh-aw/analysis/historical/ 2>/dev/null | wc -l)\n  echo \"Loaded $HIST_COUNT days of historical data\"\nelse\n  echo \"No historical data found (first run)\"\nfi"

      # Repo memory git-based storage configuration from frontmatter processed below
      - name: Clone repo-memory branch (default)
        env:
          GH_TOKEN: ${{ github.token }}
          BRANCH_NAME: memory/default
          TARGET_REPO: ${{ github.repository }}
          MEMORY_DIR: /tmp/gh-aw/repo-memory/default
          CREATE_ORPHAN: true
        run: bash /opt/gh-aw/actions/clone_repo_memory_branch.sh
      - name: Configure Git credentials
        env:
          REPO_NAME: ${{ github.repository }}
          SERVER_URL: ${{ github.server_url }}
        run: |
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"
          # Re-authenticate git with GitHub token
          SERVER_URL_STRIPPED="${SERVER_URL#https://}"
          git remote set-url origin "https://x-access-token:${{ github.token }}@${SERVER_URL_STRIPPED}/${REPO_NAME}.git"
          echo "Git configured with standard GitHub Actions identity"
      - name: Checkout PR branch
        if: |
          github.event.pull_request
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        env:
          GH_TOKEN: ${{ secrets.GH_AW_GITHUB_MCP_SERVER_TOKEN || secrets.GH_AW_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}
        with:
          github-token: ${{ secrets.GH_AW_GITHUB_MCP_SERVER_TOKEN || secrets.GH_AW_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/checkout_pr_branch.cjs');
            await main();
      - name: Validate COPILOT_GITHUB_TOKEN secret
        run: /opt/gh-aw/actions/validate_multi_secret.sh COPILOT_GITHUB_TOKEN 'GitHub Copilot CLI' https://githubnext.github.io/gh-aw/reference/engines/#github-copilot-default
        env:
          COPILOT_GITHUB_TOKEN: ${{ secrets.COPILOT_GITHUB_TOKEN }}
      - name: Install GitHub Copilot CLI
        run: |
          # Download official Copilot CLI installer script
          curl -fsSL https://raw.githubusercontent.com/github/copilot-cli/main/install.sh -o /tmp/copilot-install.sh
          
          # Execute the installer with the specified version
          # Pass VERSION directly to sudo to ensure it's available to the installer script
          sudo VERSION=0.0.384 bash /tmp/copilot-install.sh
          
          # Cleanup
          rm -f /tmp/copilot-install.sh
          
          # Verify installation
          copilot --version
      - name: Install awf binary
        run: |
          echo "Installing awf via installer script (requested version: v0.9.1)"
          curl -sSL https://raw.githubusercontent.com/githubnext/gh-aw-firewall/main/install.sh | sudo AWF_VERSION=v0.9.1 bash
          which awf
          awf --version
      - name: Determine automatic lockdown mode for GitHub MCP server
        id: determine-automatic-lockdown
        env:
          TOKEN_CHECK: ${{ secrets.GH_AW_GITHUB_MCP_SERVER_TOKEN }}
        if: env.TOKEN_CHECK != ''
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const determineAutomaticLockdown = require('/opt/gh-aw/actions/determine_automatic_lockdown.cjs');
            await determineAutomaticLockdown(github, context, core);
      - name: Download container images
        run: bash /opt/gh-aw/actions/download_docker_images.sh ghcr.io/github/github-mcp-server:v0.28.1 ghcr.io/githubnext/gh-aw-mcpg:v0.0.62
      - name: Start MCP gateway
        id: start-mcp-gateway
        env:
          GITHUB_MCP_LOCKDOWN: ${{ steps.determine-automatic-lockdown.outputs.lockdown == 'true' && '1' || '0' }}
          GITHUB_MCP_SERVER_TOKEN: ${{ secrets.GH_AW_GITHUB_MCP_SERVER_TOKEN || secrets.GH_AW_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}
        run: |
          set -eo pipefail
          mkdir -p /tmp/gh-aw/mcp-config
          
          # Export gateway environment variables for MCP config and gateway script
          export MCP_GATEWAY_PORT="80"
          export MCP_GATEWAY_DOMAIN="host.docker.internal"
          MCP_GATEWAY_API_KEY=""
          MCP_GATEWAY_API_KEY=$(openssl rand -base64 45 | tr -d '/+=')
          export MCP_GATEWAY_API_KEY
          
          # Register API key as secret to mask it from logs
          echo "::add-mask::${MCP_GATEWAY_API_KEY}"
          export GH_AW_ENGINE="copilot"
          export MCP_GATEWAY_DOCKER_COMMAND='docker run -i --rm --network host -v /var/run/docker.sock:/var/run/docker.sock -e MCP_GATEWAY_PORT -e MCP_GATEWAY_DOMAIN -e MCP_GATEWAY_API_KEY -e DEBUG="*" -e MCP_GATEWAY_LOG_DIR -e GH_AW_MCP_LOG_DIR -e GH_AW_SAFE_OUTPUTS -e GH_AW_SAFE_OUTPUTS_CONFIG_PATH -e GH_AW_SAFE_OUTPUTS_TOOLS_PATH -e GH_AW_ASSETS_BRANCH -e GH_AW_ASSETS_MAX_SIZE_KB -e GH_AW_ASSETS_ALLOWED_EXTS -e DEFAULT_BRANCH -e GITHUB_MCP_SERVER_TOKEN -e GITHUB_MCP_LOCKDOWN -e GITHUB_REPOSITORY -e GITHUB_SERVER_URL -e GITHUB_SHA -e GITHUB_WORKSPACE -e GITHUB_TOKEN -v /opt:/opt:ro -v /tmp:/tmp:rw -v '"${GITHUB_WORKSPACE}"':'"${GITHUB_WORKSPACE}"':rw ghcr.io/githubnext/gh-aw-mcpg:v0.0.62'
          
          mkdir -p /home/runner/.copilot
          cat << MCPCONFIG_EOF | bash /opt/gh-aw/actions/start_mcp_gateway.sh
          {
            "mcpServers": {
              "github": {
                "type": "stdio",
                "container": "ghcr.io/github/github-mcp-server:v0.28.1",
                "env": {
                  "GITHUB_LOCKDOWN_MODE": "$GITHUB_MCP_LOCKDOWN",
                  "GITHUB_PERSONAL_ACCESS_TOKEN": "\${GITHUB_MCP_SERVER_TOKEN}",
                  "GITHUB_READ_ONLY": "1",
                  "GITHUB_TOOLSETS": "context,repos,issues,pull_requests"
                }
              }
            },
            "gateway": {
              "port": $MCP_GATEWAY_PORT,
              "domain": "${MCP_GATEWAY_DOMAIN}",
              "apiKey": "${MCP_GATEWAY_API_KEY}"
            }
          }
          MCPCONFIG_EOF
      - name: Generate agentic run info
        id: generate_aw_info
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');
            
            const awInfo = {
              engine_id: "copilot",
              engine_name: "GitHub Copilot CLI",
              model: process.env.GH_AW_MODEL_AGENT_COPILOT || "",
              version: "",
              agent_version: "0.0.384",
              workflow_name: "Test GitHub Data Analysis Framework",
              experimental: false,
              supports_tools_allowlist: true,
              supports_http_transport: true,
              run_id: context.runId,
              run_number: context.runNumber,
              run_attempt: process.env.GITHUB_RUN_ATTEMPT,
              repository: context.repo.owner + '/' + context.repo.repo,
              ref: context.ref,
              sha: context.sha,
              actor: context.actor,
              event_name: context.eventName,
              staged: false,
              network_mode: "defaults",
              allowed_domains: [],
              firewall_enabled: true,
              awf_version: "v0.9.1",
              awmg_version: "v0.0.62",
              steps: {
                firewall: "squid"
              },
              created_at: new Date().toISOString()
            };
            
            // Write to /tmp/gh-aw directory to avoid inclusion in PR
            const tmpPath = '/tmp/gh-aw/aw_info.json';
            fs.writeFileSync(tmpPath, JSON.stringify(awInfo, null, 2));
            console.log('Generated aw_info.json at:', tmpPath);
            console.log(JSON.stringify(awInfo, null, 2));
            
            // Set model as output for reuse in other steps/jobs
            core.setOutput('model', awInfo.model);
      - name: Generate workflow overview
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const { generateWorkflowOverview } = require('/opt/gh-aw/actions/generate_workflow_overview.cjs');
            await generateWorkflowOverview(core);
      - name: Create prompt
        env:
          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt
        run: |
          bash /opt/gh-aw/actions/create_prompt_first.sh
          cat << 'PROMPT_EOF' > "$GH_AW_PROMPT"
          # GitHub Data Analysis Framework
          
          This shared component provides a standardized framework for workflows that analyze GitHub data with persistent storage and trend tracking.
          
          ## Features
          
          - **Persistent storage** with repo-memory for historical data
          - **Structured directories** for organized data management
          - **Historical data loading** (last 30 days automatically)
          - **Trend calculation helpers** for 7-day and 30-day comparisons
          - **Standardized metrics storage** format
          
          ## Directory Structure
          
          ```
          /tmp/gh-aw/analysis/
          ├── data/          # Current run data and inputs
          ├── historical/    # Last 30 days for comparison
          └── output/        # Analysis results and reports
          
          /tmp/gh-aw/repo-memory/default/
          └── metrics/
              └── daily/     # Daily metrics stored as YYYY-MM-DD.json
          ```
          
          ## Trend Calculation Helpers
          
          The following bash functions are available for calculating trends:
          
          ### calculate_trend
          
          Calculate percentage change between two values:
          
          ```bash
          # Calculate percentage change between two values
          calculate_trend() {
            local current=$1
            local previous=$2
            
            if [ -z "$previous" ] || [ "$previous" = "0" ] || [ "$previous" = "null" ]; then
              echo "N/A"
              return
            fi
            
            local change=$(echo "scale=2; (($current - $previous) / $previous) * 100" | bc)
            printf "%.1f" "$change"
          }
          
          # Usage example:
          current_value=100
          previous_value=80
          trend=$(calculate_trend "$current_value" "$previous_value")
          echo "Trend: ${trend}%"  # Output: Trend: 25.0%
          ```
          
          ### get_trend_indicator
          
          Get trend indicator emoji based on percentage change:
          
          ```bash
          # Get trend indicator emoji
          get_trend_indicator() {
            local change=$1
            
            if [ "$change" = "N/A" ]; then
              echo "➡️"
            elif (( $(echo "$change > 10" | bc -l) )); then
              echo "⬆️"
            elif (( $(echo "$change < -10" | bc -l) )); then
              echo "⬇️"
            else
              echo "➡️"
            fi
          }
          
          # Usage example:
          trend_7d=25.0
          indicator=$(get_trend_indicator "$trend_7d")
          echo "7-day trend: ${indicator} ${trend_7d}%"  # Output: 7-day trend: ⬆️ 25.0%
          ```
          
          ### get_historical_value
          
          Get value from N days ago from historical data:
          
          ```bash
          # Get value from N days ago
          get_historical_value() {
            local metric_path=$1
            local days_ago=$2
            
            # Cross-platform date handling (GNU date first, BSD fallback)
            local target_date=$(date -d "$days_ago days ago" '+%Y-%m-%d' 2>/dev/null || \
                                date -v-${days_ago}d '+%Y-%m-%d')
            local hist_file="/tmp/gh-aw/analysis/historical/${target_date}.json"
            
            if [ -f "$hist_file" ]; then
              jq -r "$metric_path // null" "$hist_file"
            else
              echo "null"
            fi
          }
          
          # Usage example:
          value_7d_ago=$(get_historical_value '.metrics.total_count' 7)
          value_30d_ago=$(get_historical_value '.metrics.total_count' 30)
          echo "7 days ago: $value_7d_ago"
          echo "30 days ago: $value_30d_ago"
          ```
          
          ## Storage Pattern
          
          Store daily metrics in standardized format:
          
          ```bash
          # Store current run metrics
          TODAY=$(date +%Y-%m-%d)
          METRICS_FILE="/tmp/gh-aw/repo-memory/default/metrics/daily/${TODAY}.json"
          
          # Example: Create metrics JSON with jq
          jq -n \
            --arg date "$TODAY" \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            --argjson metrics "$metrics_json" \
            '{
              date: $date,
              timestamp: $timestamp,
              metrics: $metrics
            }' > "$METRICS_FILE"
          
          echo "Metrics stored: $METRICS_FILE"
          ```
          
          ### Metrics JSON Structure
          
          All metrics should follow this structure:
          
          ```json
          {
            "date": "2026-01-16",
            "timestamp": "2026-01-16T12:00:00Z",
            "metrics": {
              "total_count": 100,
              "open_count": 45,
              "closed_count": 55,
              "custom_metric_1": 42,
              "custom_metric_2": "some_value"
            }
          }
          ```
          
          ## Trend Analysis Pattern
          
          Complete example of calculating trends:
          
          ```bash
          # Calculate 7-day and 30-day trends
          current_value=100
          value_7d_ago=$(get_historical_value '.metrics.total_count' 7)
          value_30d_ago=$(get_historical_value '.metrics.total_count' 30)
          
          trend_7d=$(calculate_trend "$current_value" "$value_7d_ago")
          trend_30d=$(calculate_trend "$current_value" "$value_30d_ago")
          
          indicator_7d=$(get_trend_indicator "$trend_7d")
          indicator_30d=$(get_trend_indicator "$trend_30d")
          
          echo "Current: $current_value"
          echo "7-day change: ${indicator_7d} ${trend_7d}%"
          echo "30-day change: ${indicator_30d} ${trend_30d}%"
          ```
          
          ## Complete Usage Example
          
          Here's a complete workflow using the framework:
          
          ```yaml
          ---
          imports:
            - shared/github-data-analysis-framework.md
            - shared/issues-data-fetch.md
            
          tools:
            github:
              toolsets: [default]
          
          timeout-minutes: 20
          ---
          
          # Your workflow prompt
          
          ## Step 1: Load and Analyze Data
          
          # Analysis environment is already set up by the framework
          # Load your current data
          cp /tmp/gh-aw/issues-data/issues.json /tmp/gh-aw/analysis/data/
          
          # Perform analysis
          current_total=$(jq 'length' /tmp/gh-aw/analysis/data/issues.json)
          current_open=$(jq '[.[] | select(.state == "OPEN")] | length' /tmp/gh-aw/analysis/data/issues.json)
          
          ## Step 2: Calculate Trends
          
          # Get historical values
          total_7d_ago=$(get_historical_value '.metrics.total_issues' 7)
          total_30d_ago=$(get_historical_value '.metrics.total_issues' 30)
          
          # Calculate trends
          trend_7d=$(calculate_trend "$current_total" "$total_7d_ago")
          trend_30d=$(calculate_trend "$current_total" "$total_30d_ago")
          
          # Get indicators
          indicator_7d=$(get_trend_indicator "$trend_7d")
          indicator_30d=$(get_trend_indicator "$trend_30d")
          
          ## Step 3: Store Results
          
          TODAY=$(date +%Y-%m-%d)
          METRICS_FILE="/tmp/gh-aw/repo-memory/default/metrics/daily/${TODAY}.json"
          
          jq -n \
            --arg date "$TODAY" \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            --argjson total "$current_total" \
            --argjson open "$current_open" \
            --arg trend_7d "$trend_7d" \
            --arg trend_30d "$trend_30d" \
            '{
              date: $date,
              timestamp: $timestamp,
              metrics: {
                total_issues: $total,
                open_issues: $open,
                trend_7d: $trend_7d,
                trend_30d: $trend_30d
              }
            }' > "$METRICS_FILE"
          
          echo "Metrics stored to: $METRICS_FILE"
          
          ## Step 4: Generate Report
          
          echo "# Daily Report - $TODAY"
          echo ""
          echo "## Metrics"
          echo "- Total issues: $current_total"
          echo "- Open issues: $current_open"
          echo "- 7-day trend: ${indicator_7d} ${trend_7d}%"
          echo "- 30-day trend: ${indicator_30d} ${trend_30d}%"
          ```
          
          ## Best Practices
          
          1. **Consistent metric names**: Use same field names across runs for trend tracking
          2. **Date-based files**: Always use YYYY-MM-DD.json format for daily metrics
          3. **Null handling**: Check for null/missing historical data before calculations
          4. **Cross-platform**: Use compatible date commands (GNU date with BSD fallback)
          5. **Validation**: Verify historical files exist before loading
          6. **bc availability**: Ensure `bc` is installed for floating-point calculations
          7. **Error handling**: Gracefully handle missing historical data (first run)
          
          ## Cross-Platform Compatibility
          
          ### Date Commands
          
          Always use the cross-platform date pattern:
          
          ```bash
          # GNU date (Linux) first, then BSD date (macOS) fallback
          TARGET_DATE=$(date -d "7 days ago" '+%Y-%m-%d' 2>/dev/null || \
                        date -v-7d '+%Y-%m-%d')
          ```
          
          ### bc Commands
          
          For floating-point calculations, use `bc` with proper scale:
          
          ```bash
          # Calculate with 2 decimal places
          result=$(echo "scale=2; 100 / 3" | bc)
          # Output: 33.33
          
          # Format output with printf
          formatted=$(printf "%.1f" "$result")
          ```
          
          ## Helper Functions in Action
          
          Copy this into your workflow for easy access to all helpers:
          
          ```bash
          # Calculate percentage change between two values
          calculate_trend() {
            local current=$1
            local previous=$2
            
            if [ -z "$previous" ] || [ "$previous" = "0" ] || [ "$previous" = "null" ]; then
              echo "N/A"
              return
            fi
            
            local change=$(echo "scale=2; (($current - $previous) / $previous) * 100" | bc)
            printf "%.1f" "$change"
          }
          
          # Get trend indicator emoji
          get_trend_indicator() {
            local change=$1
            
            if [ "$change" = "N/A" ]; then
              echo "➡️"
            elif (( $(echo "$change > 10" | bc -l) )); then
              echo "⬆️"
            elif (( $(echo "$change < -10" | bc -l) )); then
              echo "⬇️"
            else
              echo "➡️"
            fi
          }
          
          # Get value from N days ago
          get_historical_value() {
            local metric_path=$1
            local days_ago=$2
            
            local target_date=$(date -d "$days_ago days ago" '+%Y-%m-%d' 2>/dev/null || \
                                date -v-${days_ago}d '+%Y-%m-%d')
            local hist_file="/tmp/gh-aw/analysis/historical/${target_date}.json"
            
            if [ -f "$hist_file" ]; then
              jq -r "$metric_path // null" "$hist_file"
            else
              echo "null"
            fi
          }
          ```
          
          ## Troubleshooting
          
          ### Missing Historical Data
          
          On first run or when historical data is unavailable:
          
          ```bash
          value=$(get_historical_value '.metrics.count' 7)
          if [ "$value" = "null" ]; then
            echo "No historical data available for comparison"
            # Skip trend calculation or use fallback value
          fi
          ```
          
          ### bc Not Found
          
          If `bc` is not available (rare):
          
          ```bash
          if ! command -v bc &> /dev/null; then
            echo "bc is not installed, skipping trend calculations"
            # Use alternative approach or skip trends
          fi
          ```
          
          ### Date Command Differences
          
          The framework uses cross-platform date handling. If you need custom date operations:
          
          ```bash
          # Always try GNU date first, then BSD date
          custom_date=$(date -d "3 months ago" '+%Y-%m-%d' 2>/dev/null || \
                        date -v-3m '+%Y-%m-%d')
          ```
          
          ## Integration with Other Shared Components
          
          This framework works well with:
          
          - **shared/issues-data-fetch.md** - Fetch issues data for analysis
          - **shared/copilot-pr-data-fetch.md** - Fetch PR data for analysis
          - **shared/trends.md** - Advanced visualization with Python
          - **shared/python-dataviz.md** - Create charts from metrics
          - **shared/reporting.md** - Format reports with metrics
          
          Example combining multiple shared components:
          
          ```yaml
          imports:
            - shared/github-data-analysis-framework.md
            - shared/issues-data-fetch.md
            - shared/python-dataviz.md
            - shared/reporting.md
          ```
          
          # Test GitHub Data Analysis Framework
          
          This is a test workflow to validate the shared GitHub Data Analysis Framework component.
          
          ## Test 1: Verify Directory Setup
          
          Check that the analysis directories were created:
          
          ```bash
          echo "Checking directory structure..."
          ls -la /tmp/gh-aw/analysis/
          ls -la /tmp/gh-aw/repo-memory/default/metrics/
          echo "✓ Directory structure verified"
          ```
          
          ## Test 2: Test Helper Functions
          
          Define and test the helper functions:
          
          ```bash
          # Define helper functions
          calculate_trend() {
            local current=$1
            local previous=$2
            
            if [ -z "$previous" ] || [ "$previous" = "0" ] || [ "$previous" = "null" ]; then
              echo "N/A"
              return
            fi
            
            local change=$(echo "scale=2; (($current - $previous) / $previous) * 100" | bc)
            printf "%.1f" "$change"
          }
          
          get_trend_indicator() {
            local change=$1
            
            if [ "$change" = "N/A" ]; then
              echo "➡️"
            elif (( $(echo "$change > 10" | bc -l) )); then
              echo "⬆️"
            elif (( $(echo "$change < -10" | bc -l) )); then
              echo "⬇️"
            else
              echo "➡️"
            fi
          }
          
          # Test trend calculation
          echo "Testing trend calculations..."
          trend1=$(calculate_trend 100 80)
          echo "Trend (100 vs 80): ${trend1}% (expected: 25.0%)"
          
          trend2=$(calculate_trend 80 100)
          echo "Trend (80 vs 100): ${trend2}% (expected: -20.0%)"
          
          trend3=$(calculate_trend 100 0)
          echo "Trend (100 vs 0): ${trend3} (expected: N/A)"
          
          # Test indicators
          indicator1=$(get_trend_indicator "25.0")
          echo "Indicator for +25%: ${indicator1} (expected: ⬆️)"
          
          indicator2=$(get_trend_indicator "-25.0")
          echo "Indicator for -25%: ${indicator2} (expected: ⬇️)"
          
          indicator3=$(get_trend_indicator "5.0")
          echo "Indicator for +5%: ${indicator3} (expected: ➡️)"
          
          echo "✓ Helper functions tested"
          ```
          
          ## Test 3: Test Metrics Storage
          
          Create and store sample metrics:
          
          ```bash
          echo "Testing metrics storage..."
          
          TODAY=$(date +%Y-%m-%d)
          METRICS_FILE="/tmp/gh-aw/repo-memory/default/metrics/daily/${TODAY}.json"
          
          # Create sample metrics
          jq -n \
            --arg date "$TODAY" \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            --argjson total 42 \
            --argjson active 15 \
            '{
              date: $date,
              timestamp: $timestamp,
              metrics: {
                total_items: $total,
                active_items: $active
              }
            }' > "$METRICS_FILE"
          
          echo "Metrics stored to: $METRICS_FILE"
          
          # Verify stored metrics
          if [ -f "$METRICS_FILE" ]; then
            echo "✓ Metrics file created successfully"
            jq '.' "$METRICS_FILE"
          else
            echo "✗ Failed to create metrics file"
            exit 1
          fi
          ```
          
          ## Test 4: Test Historical Data Loading
          
          Test loading historical data:
          
          ```bash
          echo "Testing historical data loading..."
          
          # Create some historical data for testing (simulate 3 days ago)
          for days_ago in 3 7 15; do
            hist_date=$(date -d "$days_ago days ago" '+%Y-%m-%d' 2>/dev/null || \
                        date -v-${days_ago}d '+%Y-%m-%d')
            hist_file="/tmp/gh-aw/repo-memory/default/metrics/daily/${hist_date}.json"
            
            jq -n \
              --arg date "$hist_date" \
              --argjson total "$((40 + days_ago))" \
              '{
                date: $date,
                metrics: {
                  total_items: $total
                }
              }' > "$hist_file"
            
            echo "Created historical data: $hist_file"
          done
          
          # Trigger historical data loading (re-run the load step conceptually)
          HISTORY_DIR="/tmp/gh-aw/repo-memory/default/metrics/daily"
          if [ -d "$HISTORY_DIR" ]; then
            find "$HISTORY_DIR" -name "*.json" -mtime -30 \
              -exec cp {} /tmp/gh-aw/analysis/historical/ \; 2>/dev/null || true
            
            HIST_COUNT=$(ls -1 /tmp/gh-aw/analysis/historical/ 2>/dev/null | wc -l)
            echo "Loaded $HIST_COUNT days of historical data"
            ls -l /tmp/gh-aw/analysis/historical/
            echo "✓ Historical data loading verified"
          fi
          ```
          
          ## Test 5: Complete Integration Test
          
          Run a complete analysis workflow:
          
          ```bash
          echo "Running complete integration test..."
          
          # Define helper functions
          get_historical_value() {
            local metric_path=$1
            local days_ago=$2
            
            local target_date=$(date -d "$days_ago days ago" '+%Y-%m-%d' 2>/dev/null || \
                                date -v-${days_ago}d '+%Y-%m-%d')
            local hist_file="/tmp/gh-aw/analysis/historical/${target_date}.json"
            
            if [ -f "$hist_file" ]; then
              jq -r "$metric_path // null" "$hist_file"
            else
              echo "null"
            fi
          }
          
          # Current metrics
          current_total=42
          
          # Get historical values
          total_7d_ago=$(get_historical_value '.metrics.total_items' 7)
          echo "7 days ago: $total_7d_ago"
          
          # Calculate trend
          if [ "$total_7d_ago" != "null" ]; then
            trend_7d=$(calculate_trend "$current_total" "$total_7d_ago")
            indicator_7d=$(get_trend_indicator "$trend_7d")
            
            echo ""
            echo "=== Analysis Results ==="
            echo "Current total: $current_total"
            echo "7 days ago: $total_7d_ago"
            echo "7-day trend: ${indicator_7d} ${trend_7d}%"
            echo "✓ Complete integration test passed"
          else
            echo "Note: No historical data from 7 days ago (expected on first run)"
          fi
          ```
          
          ## Success Criteria
          
          All tests should pass:
          - ✓ Directory structure created
          - ✓ Helper functions work correctly
          - ✓ Metrics storage successful
          - ✓ Historical data loading works
          - ✓ Complete integration test passes
          
          If any test fails, the framework needs adjustment.
          
          PROMPT_EOF
      - name: Append context instructions to prompt
        env:
          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt
          GH_AW_GITHUB_ACTOR: ${{ github.actor }}
          GH_AW_GITHUB_EVENT_COMMENT_ID: ${{ github.event.comment.id }}
          GH_AW_GITHUB_EVENT_DISCUSSION_NUMBER: ${{ github.event.discussion.number }}
          GH_AW_GITHUB_EVENT_ISSUE_NUMBER: ${{ github.event.issue.number }}
          GH_AW_GITHUB_EVENT_PULL_REQUEST_NUMBER: ${{ github.event.pull_request.number }}
          GH_AW_GITHUB_REPOSITORY: ${{ github.repository }}
          GH_AW_GITHUB_RUN_ID: ${{ github.run_id }}
          GH_AW_GITHUB_WORKSPACE: ${{ github.workspace }}
        run: |
          cat "/opt/gh-aw/prompts/temp_folder_prompt.md" >> "$GH_AW_PROMPT"
          cat << 'PROMPT_EOF' >> "$GH_AW_PROMPT"
          
          ---
          
          ## Repo Memory Available
          
          You have access to a persistent repo memory folder at `/tmp/gh-aw/repo-memory/default/` where you can read and write files that are stored in a git branch. Shared data analysis storage
          
          - **Read/Write Access**: You can freely read from and write to any files in this folder
          - **Git Branch Storage**: Files are stored in the `memory/default` branch of the current repository
          - **Automatic Push**: Changes are automatically committed and pushed after the workflow completes
          - **Merge Strategy**: In case of conflicts, your changes (current version) win
          - **Persistence**: Files persist across workflow runs via git branch storage
          
          **Constraints:**
          - **Allowed Files**: Only files matching patterns: *.json, *.jsonl, *.csv, *.md
          - **Max File Size**: 102400 bytes (0.10 MB) per file
          - **Max File Count**: 100 files per commit
          
          Examples of what you can store:
          - `/tmp/gh-aw/repo-memory/default/notes.md` - general notes and observations
          - `/tmp/gh-aw/repo-memory/default/state.json` - structured state data
          - `/tmp/gh-aw/repo-memory/default/history/` - organized history files in subdirectories
          
          Feel free to create, read, update, and organize files in this folder as needed for your tasks.
          
          <github-context>
          The following GitHub context information is available for this workflow:
          {{#if __GH_AW_GITHUB_ACTOR__ }}
          - **actor**: __GH_AW_GITHUB_ACTOR__
          {{/if}}
          {{#if __GH_AW_GITHUB_REPOSITORY__ }}
          - **repository**: __GH_AW_GITHUB_REPOSITORY__
          {{/if}}
          {{#if __GH_AW_GITHUB_WORKSPACE__ }}
          - **workspace**: __GH_AW_GITHUB_WORKSPACE__
          {{/if}}
          {{#if __GH_AW_GITHUB_EVENT_ISSUE_NUMBER__ }}
          - **issue-number**: #__GH_AW_GITHUB_EVENT_ISSUE_NUMBER__
          {{/if}}
          {{#if __GH_AW_GITHUB_EVENT_DISCUSSION_NUMBER__ }}
          - **discussion-number**: #__GH_AW_GITHUB_EVENT_DISCUSSION_NUMBER__
          {{/if}}
          {{#if __GH_AW_GITHUB_EVENT_PULL_REQUEST_NUMBER__ }}
          - **pull-request-number**: #__GH_AW_GITHUB_EVENT_PULL_REQUEST_NUMBER__
          {{/if}}
          {{#if __GH_AW_GITHUB_EVENT_COMMENT_ID__ }}
          - **comment-id**: __GH_AW_GITHUB_EVENT_COMMENT_ID__
          {{/if}}
          {{#if __GH_AW_GITHUB_RUN_ID__ }}
          - **workflow-run-id**: __GH_AW_GITHUB_RUN_ID__
          {{/if}}
          </github-context>
          
          PROMPT_EOF
      - name: Interpolate variables and render templates
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        env:
          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt
        with:
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/interpolate_prompt.cjs');
            await main();
      - name: Print prompt
        env:
          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt
        run: bash /opt/gh-aw/actions/print_prompt_summary.sh
      - name: Execute GitHub Copilot CLI
        id: agentic_execution
        # Copilot CLI tool arguments (sorted):
        # --allow-tool github
        # --allow-tool shell(bc *)
        # --allow-tool shell(cat *)
        # --allow-tool shell(cat)
        # --allow-tool shell(cp *)
        # --allow-tool shell(date *)
        # --allow-tool shell(date)
        # --allow-tool shell(echo)
        # --allow-tool shell(find *)
        # --allow-tool shell(grep)
        # --allow-tool shell(head)
        # --allow-tool shell(jq *)
        # --allow-tool shell(ls *)
        # --allow-tool shell(ls)
        # --allow-tool shell(mkdir *)
        # --allow-tool shell(pwd)
        # --allow-tool shell(sort)
        # --allow-tool shell(tail)
        # --allow-tool shell(uniq)
        # --allow-tool shell(wc *)
        # --allow-tool shell(wc)
        # --allow-tool shell(yq)
        # --allow-tool write
        timeout-minutes: 5
        run: |
          set -o pipefail
          sudo -E awf --env-all --container-workdir "${GITHUB_WORKSPACE}" --mount /tmp:/tmp:rw --mount "${GITHUB_WORKSPACE}:${GITHUB_WORKSPACE}:rw" --mount /usr/bin/date:/usr/bin/date:ro --mount /usr/bin/gh:/usr/bin/gh:ro --mount /usr/bin/yq:/usr/bin/yq:ro --mount /usr/local/bin/copilot:/usr/local/bin/copilot:ro --mount /home/runner/.copilot:/home/runner/.copilot:rw --mount /opt/gh-aw:/opt/gh-aw:ro --allow-domains api.business.githubcopilot.com,api.enterprise.githubcopilot.com,api.github.com,api.githubcopilot.com,api.individual.githubcopilot.com,github.com,host.docker.internal,raw.githubusercontent.com,registry.npmjs.org --log-level info --proxy-logs-dir /tmp/gh-aw/sandbox/firewall/logs --enable-host-access --image-tag 0.9.1 \
            -- /usr/local/bin/copilot --add-dir /tmp/gh-aw/ --log-level all --log-dir /tmp/gh-aw/sandbox/agent/logs/ --add-dir "${GITHUB_WORKSPACE}" --disable-builtin-mcps --allow-tool github --allow-tool 'shell(bc *)' --allow-tool 'shell(cat *)' --allow-tool 'shell(cat)' --allow-tool 'shell(cp *)' --allow-tool 'shell(date *)' --allow-tool 'shell(date)' --allow-tool 'shell(echo)' --allow-tool 'shell(find *)' --allow-tool 'shell(grep)' --allow-tool 'shell(head)' --allow-tool 'shell(jq *)' --allow-tool 'shell(ls *)' --allow-tool 'shell(ls)' --allow-tool 'shell(mkdir *)' --allow-tool 'shell(pwd)' --allow-tool 'shell(sort)' --allow-tool 'shell(tail)' --allow-tool 'shell(uniq)' --allow-tool 'shell(wc *)' --allow-tool 'shell(wc)' --allow-tool 'shell(yq)' --allow-tool write --allow-all-paths --share /tmp/gh-aw/sandbox/agent/logs/conversation.md --prompt "$(cat /tmp/gh-aw/aw-prompts/prompt.txt)"${GH_AW_MODEL_DETECTION_COPILOT:+ --model "$GH_AW_MODEL_DETECTION_COPILOT"} \
            2>&1 | tee /tmp/gh-aw/agent-stdio.log
        env:
          COPILOT_AGENT_RUNNER_TYPE: STANDALONE
          COPILOT_GITHUB_TOKEN: ${{ secrets.COPILOT_GITHUB_TOKEN }}
          GH_AW_MCP_CONFIG: /home/runner/.copilot/mcp-config.json
          GH_AW_MODEL_DETECTION_COPILOT: ${{ vars.GH_AW_MODEL_DETECTION_COPILOT || '' }}
          GH_AW_PROMPT: /tmp/gh-aw/aw-prompts/prompt.txt
          GITHUB_HEAD_REF: ${{ github.head_ref }}
          GITHUB_REF_NAME: ${{ github.ref_name }}
          GITHUB_STEP_SUMMARY: ${{ env.GITHUB_STEP_SUMMARY }}
          GITHUB_WORKSPACE: ${{ github.workspace }}
          XDG_CONFIG_HOME: /home/runner
      - name: Copy Copilot session state files to logs
        if: always()
        continue-on-error: true
        run: |
          # Copy Copilot session state files to logs folder for artifact collection
          # This ensures they are in /tmp/gh-aw/ where secret redaction can scan them
          SESSION_STATE_DIR="$HOME/.copilot/session-state"
          LOGS_DIR="/tmp/gh-aw/sandbox/agent/logs"
          
          if [ -d "$SESSION_STATE_DIR" ]; then
            echo "Copying Copilot session state files from $SESSION_STATE_DIR to $LOGS_DIR"
            mkdir -p "$LOGS_DIR"
            cp -v "$SESSION_STATE_DIR"/*.jsonl "$LOGS_DIR/" 2>/dev/null || true
            echo "Session state files copied successfully"
          else
            echo "No session-state directory found at $SESSION_STATE_DIR"
          fi
      - name: Stop MCP gateway
        if: always()
        continue-on-error: true
        env:
          MCP_GATEWAY_PORT: ${{ steps.start-mcp-gateway.outputs.gateway-port }}
          MCP_GATEWAY_API_KEY: ${{ steps.start-mcp-gateway.outputs.gateway-api-key }}
          GATEWAY_PID: ${{ steps.start-mcp-gateway.outputs.gateway-pid }}
        run: |
          bash /opt/gh-aw/actions/stop_mcp_gateway.sh "$GATEWAY_PID"
      - name: Redact secrets in logs
        if: always()
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/redact_secrets.cjs');
            await main();
        env:
          GH_AW_SECRET_NAMES: 'COPILOT_GITHUB_TOKEN,GH_AW_GITHUB_MCP_SERVER_TOKEN,GH_AW_GITHUB_TOKEN,GITHUB_TOKEN'
          SECRET_COPILOT_GITHUB_TOKEN: ${{ secrets.COPILOT_GITHUB_TOKEN }}
          SECRET_GH_AW_GITHUB_MCP_SERVER_TOKEN: ${{ secrets.GH_AW_GITHUB_MCP_SERVER_TOKEN }}
          SECRET_GH_AW_GITHUB_TOKEN: ${{ secrets.GH_AW_GITHUB_TOKEN }}
          SECRET_GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - name: Upload engine output files
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: agent_outputs
          path: |
            /tmp/gh-aw/sandbox/agent/logs/
            /tmp/gh-aw/redacted-urls.log
          if-no-files-found: ignore
      - name: Parse agent logs for step summary
        if: always()
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        env:
          GH_AW_AGENT_OUTPUT: /tmp/gh-aw/sandbox/agent/logs/
        with:
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/parse_copilot_log.cjs');
            await main();
      - name: Parse MCP gateway logs for step summary
        if: always()
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/parse_mcp_gateway_log.cjs');
            await main();
      - name: Print firewall logs
        if: always()
        continue-on-error: true
        env:
          AWF_LOGS_DIR: /tmp/gh-aw/sandbox/firewall/logs
        run: |
          # Fix permissions on firewall logs so they can be uploaded as artifacts
          # AWF runs with sudo, creating files owned by root
          sudo chmod -R a+r /tmp/gh-aw/sandbox/firewall/logs 2>/dev/null || true
          awf logs summary | tee -a "$GITHUB_STEP_SUMMARY"
      # Upload repo memory as artifacts for push job
      - name: Upload repo-memory artifact (default)
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: repo-memory-default
          path: /tmp/gh-aw/repo-memory/default
          retention-days: 1
          if-no-files-found: ignore
      - name: Upload agent artifacts
        if: always()
        continue-on-error: true
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: agent-artifacts
          path: |
            /tmp/gh-aw/aw-prompts/prompt.txt
            /tmp/gh-aw/aw_info.json
            /tmp/gh-aw/mcp-logs/
            /tmp/gh-aw/sandbox/firewall/logs/
            /tmp/gh-aw/agent-stdio.log
          if-no-files-found: ignore

  pre_activation:
    runs-on: ubuntu-slim
    permissions:
      contents: read
    outputs:
      activated: ${{ steps.check_membership.outputs.is_team_member == 'true' }}
    steps:
      - name: Checkout actions folder
        uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1
        with:
          sparse-checkout: |
            actions
          persist-credentials: false
      - name: Setup Scripts
        uses: ./actions/setup
        with:
          destination: /opt/gh-aw/actions
      - name: Check team membership for workflow
        id: check_membership
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        env:
          GH_AW_REQUIRED_ROLES: admin,maintainer,write
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/check_membership.cjs');
            await main();

  push_repo_memory:
    needs: agent
    if: always()
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout actions folder
        uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1
        with:
          sparse-checkout: |
            actions
          persist-credentials: false
      - name: Setup Scripts
        uses: ./actions/setup
        with:
          destination: /opt/gh-aw/actions
      - name: Checkout repository
        uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1
        with:
          persist-credentials: false
          sparse-checkout: .
      - name: Configure Git credentials
        env:
          REPO_NAME: ${{ github.repository }}
          SERVER_URL: ${{ github.server_url }}
        run: |
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"
          # Re-authenticate git with GitHub token
          SERVER_URL_STRIPPED="${SERVER_URL#https://}"
          git remote set-url origin "https://x-access-token:${{ github.token }}@${SERVER_URL_STRIPPED}/${REPO_NAME}.git"
          echo "Git configured with standard GitHub Actions identity"
      - name: Download repo-memory artifact (default)
        uses: actions/download-artifact@018cc2cf5baa6db3ef3c5f8a56943fffe632ef53 # v6.0.0
        continue-on-error: true
        with:
          name: repo-memory-default
          path: /tmp/gh-aw/repo-memory/default
      - name: Push repo-memory changes (default)
        if: always()
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        env:
          GH_TOKEN: ${{ github.token }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          ARTIFACT_DIR: /tmp/gh-aw/repo-memory/default
          MEMORY_ID: default
          TARGET_REPO: ${{ github.repository }}
          BRANCH_NAME: memory/default
          MAX_FILE_SIZE: 102400
          MAX_FILE_COUNT: 100
          FILE_GLOB_FILTER: "*.json *.jsonl *.csv *.md"
        with:
          script: |
            const { setupGlobals } = require('/opt/gh-aw/actions/setup_globals.cjs');
            setupGlobals(core, github, context, exec, io);
            const { main } = require('/opt/gh-aw/actions/push_repo_memory.cjs');
            await main();

