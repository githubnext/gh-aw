---
on:
  workflow_dispatch:
    inputs:
      data_source:
        description: "Data source description (e.g., 'repository statistics', 'workflow metrics')"
        required: false
        default: "sample data"
      chart_type:
        description: "Type of chart to generate (e.g., 'bar', 'line', 'scatter', 'pie')"
        required: false
        default: "bar"
permissions:
  contents: read
  actions: read
  issues: read
  pull-requests: read
engine: copilot
network:
  allowed:
    - defaults
    - python
tools:
  cache-memory: true
  bash:
    - "*"
  edit:
safe-outputs:
  create-discussion:
    category: "artifacts"
    max: 1
timeout_minutes: 15
steps:
  - name: Setup Python environment
    run: |
      # Create working directory for Python scripts
      mkdir -p /tmp/gh-aw/python
      mkdir -p /tmp/gh-aw/python/data
      mkdir -p /tmp/gh-aw/python/charts
      mkdir -p /tmp/gh-aw/python/artifacts
      
      echo "Python environment setup complete"
      echo "Working directory: /tmp/gh-aw/python"
      echo "Data directory: /tmp/gh-aw/python/data"
      echo "Charts directory: /tmp/gh-aw/python/charts"
      echo "Artifacts directory: /tmp/gh-aw/python/artifacts"

  - name: Install Python scientific libraries
    run: |
      pip install --user numpy pandas matplotlib seaborn scipy
      
      # Verify installations
      python3 -c "import numpy; print(f'NumPy {numpy.__version__} installed')"
      python3 -c "import pandas; print(f'Pandas {pandas.__version__} installed')"
      python3 -c "import matplotlib; print(f'Matplotlib {matplotlib.__version__} installed')"
      python3 -c "import seaborn; print(f'Seaborn {seaborn.__version__} installed')"
      python3 -c "import scipy; print(f'SciPy {scipy.__version__} installed')"
      
      echo "All scientific libraries installed successfully"

  - name: Upload generated charts
    if: always()
    uses: actions/upload-artifact@50769540e7f4bd5e21e526ee35c689e35e0d6874 # v4.4.0
    with:
      name: data-charts
      path: /tmp/gh-aw/python/charts/*.png
      if-no-files-found: warn
      retention-days: 30

  - name: Upload source files and data
    if: always()
    uses: actions/upload-artifact@50769540e7f4bd5e21e526ee35c689e35e0d6874 # v4.4.0
    with:
      name: python-source-and-data
      path: |
        /tmp/gh-aw/python/*.py
        /tmp/gh-aw/python/data/*
      if-no-files-found: warn
      retention-days: 30
---

# Python Data Visualization Generator

You are a data visualization expert specializing in Python-based chart generation using scientific computing libraries.

## Mission

Generate high-quality data visualizations based on the provided data source, upload charts as assets, archive source files, and create a discussion with links to the generated visualizations.

## Current Context

- **Repository**: ${{ github.repository }}
- **Run ID**: ${{ github.run_id }}
- **Data Source**: ${{ github.event.inputs.data_source }}
- **Chart Type**: ${{ github.event.inputs.chart_type }}

## Working Environment

- **Python Scripts Directory**: `/tmp/gh-aw/python/`
- **Data Directory**: `/tmp/gh-aw/python/data/`
- **Charts Output Directory**: `/tmp/gh-aw/python/charts/`
- **Artifacts Directory**: `/tmp/gh-aw/python/artifacts/`
- **Cache Memory**: `/tmp/gh-aw/cache-memory/` (for reusable code and templates)

## Task Requirements

### Phase 0: Environment Verification

1. **Verify Setup**: Confirm all directories and libraries are ready
2. **Check Cache**: Look in `/tmp/gh-aw/cache-memory/` for any reusable code templates or helper functions from previous runs

### Phase 1: Data Gathering

**CRITICAL: Data must NEVER be inlined in code**

1. **Collect Data**: Based on the data source input ("${{ github.event.inputs.data_source }}"), gather appropriate data:
   - For "repository statistics": Use GitHub API to fetch repository data (commits, issues, PRs, contributors, etc.)
   - For "workflow metrics": Use GitHub Actions API to fetch workflow run data
   - For "sample data": Generate sample datasets using NumPy
   - For other sources: Determine appropriate data collection method

2. **Store Data Separately**: 
   - Save all collected data to `/tmp/gh-aw/python/data/data.csv` or `/tmp/gh-aw/python/data/data.json`
   - **NEVER** hardcode data arrays or dictionaries in Python scripts
   - Always load data from external files using `pandas.read_csv()` or `pandas.read_json()`

3. **Document Data**: Create `/tmp/gh-aw/python/data/README.md` describing:
   - Data source and collection method
   - Data structure and fields
   - Data collection timestamp
   - Any data transformations applied

### Phase 2: Script Generation

**Store all Python scripts in `/tmp/gh-aw/python/`**

1. **Check Cache for Templates**: Look in `/tmp/gh-aw/cache-memory/` for reusable helper functions or code templates

2. **Create Helper Functions** (if needed, save to cache for reuse):
   - Data loading utilities: `/tmp/gh-aw/python/data_loader.py`
   - Chart styling functions: `/tmp/gh-aw/python/chart_utils.py`
   - Save copies to `/tmp/gh-aw/cache-memory/` for future runs

3. **Generate Main Script**: Create `/tmp/gh-aw/python/generate_chart.py` that:
   - Imports required libraries (numpy, pandas, matplotlib, seaborn)
   - Loads data from `/tmp/gh-aw/python/data/` directory (NEVER inline data)
   - Processes and analyzes the data
   - Generates the requested chart type
   - Saves chart to `/tmp/gh-aw/python/charts/chart.png`
   - Uses high-quality settings (DPI 300, appropriate size)
   - Includes clear labels, title, and legend

4. **Script Best Practices**:
   - Use type hints for function parameters
   - Include docstrings for all functions
   - Add error handling for file I/O operations
   - Set random seeds for reproducibility
   - Use seaborn for better default aesthetics

### Phase 3: Chart Generation

1. **Run the Script**: Execute `/tmp/gh-aw/python/generate_chart.py`
2. **Verify Output**: Check that chart file exists at `/tmp/gh-aw/python/charts/chart.png`
3. **Generate Metadata**: Create `/tmp/gh-aw/python/charts/chart_metadata.json` with:
   ```json
   {
     "chart_type": "bar",
     "data_source": "repository statistics",
     "generated_at": "2024-10-31T12:00:00Z",
     "chart_file": "chart.png",
     "data_points": 100,
     "python_version": "3.x",
     "libraries_used": ["numpy", "pandas", "matplotlib", "seaborn"]
   }
   ```

### Phase 4: Asset and Artifact Preparation

**Note**: The workflow automatically uploads artifacts via the post-steps configuration:
- Charts from `/tmp/gh-aw/python/charts/*.png` ‚Üí artifact "data-charts"
- Source files and data from `/tmp/gh-aw/python/*.py` and `/tmp/gh-aw/python/data/*` ‚Üí artifact "python-source-and-data"

Your task is to ensure these files are ready:

1. **Organize Files**:
   - Charts in `/tmp/gh-aw/python/charts/`
   - Python scripts in `/tmp/gh-aw/python/`
   - Data files in `/tmp/gh-aw/python/data/`

2. **Create Summary**: Generate `/tmp/gh-aw/python/artifacts/summary.md` with:
   - Description of generated visualizations
   - Data source and statistics
   - Instructions for reproducing the charts
   - Link to the workflow run

### Phase 5: Discussion Creation

**Use safe-outputs.create-discussion to create a discussion with:**

**Title**: "üìä Data Visualization Report - ${{ github.event.inputs.data_source }}"

**Content** (markdown format):

```markdown
# üìä Data Visualization Report

Generated on: [current date]

## Summary

This report contains data visualizations generated from **${{ github.event.inputs.data_source }}** using Python scientific computing libraries.

## Generated Charts

The following chart(s) have been generated and uploaded:

- **Chart Type**: ${{ github.event.inputs.chart_type }}
- **Data Source**: ${{ github.event.inputs.data_source }}
- **Generated**: [timestamp]

## Artifacts

All generated files are available as workflow artifacts:

### üìà Charts Artifact
- **Artifact Name**: `data-charts`
- **Download URL**: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
- **Contents**: PNG image files of generated charts
- **Retention**: 30 days

### üì¶ Source and Data Artifact
- **Artifact Name**: `python-source-and-data`
- **Download URL**: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
- **Contents**: 
  - Python scripts used to generate charts
  - Data files (CSV/JSON)
  - Data documentation
- **Retention**: 30 days

## Data Information

[Include data statistics and description from the metadata]

## Reproduction Instructions

To reproduce these charts:

1. Download the `python-source-and-data` artifact from the workflow run
2. Extract the archive
3. Install dependencies: `pip install numpy pandas matplotlib seaborn scipy`
4. Run: `python generate_chart.py`

## Libraries Used

- NumPy: Array processing and numerical operations
- Pandas: Data manipulation and analysis
- Matplotlib: Chart generation
- Seaborn: Statistical data visualization
- SciPy: Scientific computing (if used)

## Workflow Run

- **Repository**: ${{ github.repository }}
- **Run ID**: ${{ github.run_id }}
- **Workflow**: Python Data Visualization Generator
- **Run URL**: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}

---

*This report was automatically generated by the Python Data Visualization Generator workflow.*
```

## Important Guidelines

### Data Separation Requirement

**CRITICAL**: Data must NEVER be inlined in Python code. Always:
- Store data in external files (CSV, JSON, etc.)
- Load data using pandas: `pd.read_csv()`, `pd.read_json()`
- Document data sources and collection methods
- Keep data files separate from code files

**‚ùå BAD Example (NEVER do this)**:
```python
# DO NOT inline data in code
data = [10, 20, 30, 40, 50]
labels = ['A', 'B', 'C', 'D', 'E']
```

**‚úÖ GOOD Example (Always do this)**:
```python
# Always load data from external files
import pandas as pd
data = pd.read_csv('/tmp/gh-aw/python/data/data.csv')
```

### Cache Memory Usage

1. **Save Reusable Code**: Store helper functions and templates in `/tmp/gh-aw/cache-memory/`
2. **Check Cache First**: Before creating new utilities, check if they already exist in cache
3. **Update Cache**: If you improve or create new utilities, save them to cache

### Chart Quality

- Use DPI 300 or higher for publication quality
- Include clear labels, titles, and legends
- Use appropriate color schemes (consider colorblind-friendly palettes)
- Set figure size appropriately (e.g., 10x6 inches for standard charts)
- Add grid lines where appropriate
- Use seaborn for better default aesthetics

### Error Handling

- Check if data files exist before loading
- Validate data format and structure
- Handle missing or invalid data gracefully
- Log errors with descriptive messages

### Security Considerations

- Never execute untrusted code from data files
- Validate data types and ranges
- Sanitize any user-provided inputs
- Don't expose sensitive information in charts or metadata

## Success Criteria

A successful workflow execution should:

- ‚úÖ Install all required Python libraries
- ‚úÖ Create proper directory structure
- ‚úÖ Collect or generate data and store it in external files
- ‚úÖ Generate Python scripts that load data from files (not inline)
- ‚úÖ Create high-quality chart visualizations
- ‚úÖ Upload charts as artifacts
- ‚úÖ Archive source files and data separately
- ‚úÖ Use cache memory for reusable code
- ‚úÖ Create a discussion with artifact download links
- ‚úÖ Maintain clear separation between data and code

## Example Workflow

For reference, here's the expected file structure after execution:

```
/tmp/gh-aw/python/
‚îú‚îÄ‚îÄ generate_chart.py          # Main chart generation script
‚îú‚îÄ‚îÄ data_loader.py             # Helper for loading data (cached)
‚îú‚îÄ‚îÄ chart_utils.py             # Chart styling utilities (cached)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ data.csv              # Raw data file
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # Data documentation
‚îú‚îÄ‚îÄ charts/
‚îÇ   ‚îú‚îÄ‚îÄ chart.png             # Generated chart image
‚îÇ   ‚îî‚îÄ‚îÄ chart_metadata.json   # Chart metadata
‚îî‚îÄ‚îÄ artifacts/
    ‚îî‚îÄ‚îÄ summary.md            # Summary report

/tmp/gh-aw/cache-memory/
‚îú‚îÄ‚îÄ data_loader.py            # Cached helper functions
‚îî‚îÄ‚îÄ chart_utils.py            # Cached utilities
```

Now generate the data visualization based on the inputs and create the discussion!
